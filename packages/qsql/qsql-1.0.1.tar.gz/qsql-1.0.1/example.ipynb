{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Using PyQuickSQL Query Loader\n",
    "In your sql file you must specify the start of a query with `-- name: queryname`, and the parameters within the query using `:paramname`.\n",
    "You can optionally end a query with `-- :end`. See `example.sql`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319cb30acf77876e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can import quicksql and load up some queries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b1a913a06d4524"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "LoadSQL(C:\\Users\\charl\\PycharmProjects\\PyQuickSQL\\example.sql)\nQuery Name: contributing_employees, Params: order_avg, num_orders\nQuery Name: customer_orders, Params: product_id, edate, sdate"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quicksql, os\n",
    "queries = quicksql.LoadSQL(os.path.join(os.getcwd(),'example.sql'))\n",
    "queries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:46:02.564164Z",
     "start_time": "2023-11-05T22:46:02.558153900Z"
    }
   },
   "id": "295f8af182edea02"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries from:: C:\\Users\\charl\\PycharmProjects\\PyQuickSQL\\example.sql\n",
      "\n",
      "-- Query:: contributing_employees\n",
      "SELECT\n",
      "  EmployeeID,\n",
      "  COUNT(OrderID) AS NumberOfOrders,\n",
      "  AVG(TotalAmount) AS AverageOrderAmount\n",
      "FROM\n",
      "  Orders\n",
      "GROUP BY\n",
      "  EmployeeID\n",
      "HAVING\n",
      "  COUNT(OrderID) > :num_orders AND AVG(TotalAmount) > :order_avg\n",
      "ORDER BY\n",
      "  AverageOrderAmount DESC;\n",
      "/* This query selects the EmployeeID, counts the number of orders, and calculates the average order amount from an Orders table.\n",
      "   It groups the results by EmployeeID, and includes only those employees who have more than :num_orders orders and where the average order amount is greater than $:order_avg.\n",
      "   It orders the results by the average order amount in descending order. */\n",
      "\n",
      "-- Query:: customer_orders\n",
      "SELECT\n",
      "  c.CustomerName,\n",
      "  o.OrderDate,\n",
      "  o.Status,\n",
      "  (SELECT SUM(od.Quantity * od.UnitPrice) FROM OrderDetails od WHERE od.OrderID = o.OrderID) AS TotalValue\n",
      "FROM\n",
      "  Customers c\n",
      "INNER JOIN Orders o ON c.CustomerID = o.CustomerID\n",
      "WHERE\n",
      "  o.OrderDate BETWEEN :sdate AND :edate\n",
      "  AND EXISTS (SELECT 1 FROM OrderDetails od WHERE od.OrderID = o.OrderID AND od.ProductID = :product_id)\n",
      "ORDER BY\n",
      "  TotalValue DESC;\n"
     ]
    }
   ],
   "source": [
    "print(str(queries))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T18:31:22.443700600Z",
     "start_time": "2023-11-04T18:31:22.439688800Z"
    }
   },
   "id": "86f00e22f6f4a42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And lastly we can produce a query given the arguments specified above."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d35b796c954508"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "  EmployeeID,\n",
      "  COUNT(OrderID) AS NumberOfOrders,\n",
      "  AVG(TotalAmount) AS AverageOrderAmount\n",
      "FROM\n",
      "  Orders\n",
      "GROUP BY\n",
      "  EmployeeID\n",
      "HAVING\n",
      "  COUNT(OrderID) > 5 AND AVG(TotalAmount) > 1000\n",
      "ORDER BY\n",
      "  AverageOrderAmount DESC;\n",
      "/* This query selects the EmployeeID, counts the number of orders, and calculates the average order amount from an Orders table.\n",
      "   It groups the results by EmployeeID, and includes only those employees who have more than 5 orders and where the average order amount is greater than $1000.\n",
      "   It orders the results by the average order amount in descending order. */\n",
      "\n",
      "\n",
      "Unused variables: something_not_a_param in query customer_orders\n",
      "SELECT\n",
      "  c.CustomerName,\n",
      "  o.OrderDate,\n",
      "  o.Status,\n",
      "  (SELECT SUM(od.Quantity * od.UnitPrice) FROM OrderDetails od WHERE od.OrderID = o.OrderID) AS TotalValue\n",
      "FROM\n",
      "  Customers c\n",
      "INNER JOIN Orders o ON c.CustomerID = o.CustomerID\n",
      "WHERE\n",
      "  o.OrderDate BETWEEN '1-10-2022' AND DATE'4-11-2023'\n",
      "  AND EXISTS (SELECT 1 FROM OrderDetails od WHERE od.OrderID = o.OrderID AND od.ProductID = 10)\n",
      "ORDER BY\n",
      "  TotalValue DESC;\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing value for variable order_avg",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(queries\u001B[38;5;241m.\u001B[39mcontributing_employees(num_orders\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,order_avg\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(queries\u001B[38;5;241m.\u001B[39mcustomer_orders(product_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,sdate\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1-10-2022\u001B[39m\u001B[38;5;124m'\u001B[39m,edate\u001B[38;5;241m=\u001B[39mquicksql\u001B[38;5;241m.\u001B[39mNoStr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATE\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4-11-2023\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m),something_not_a_param\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mqueries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontributing_employees\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_orders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\PyQuickSQL\\quicksql\\_quicksql.py:119\u001B[0m, in \u001B[0;36mQuery.__call__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m     rp\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(v[\u001B[38;5;241m1\u001B[39m],\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rp \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing value for variable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mv[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    120\u001B[0m     oq\u001B[38;5;241m=\u001B[39moq\u001B[38;5;241m.\u001B[39mreplace(v[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mstr\u001B[39m(rp) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(rp) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    121\u001B[0m chk_nkg\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mkeys()\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvars\n",
      "\u001B[1;31mValueError\u001B[0m: Missing value for variable order_avg"
     ]
    }
   ],
   "source": [
    "print(queries.contributing_employees(num_orders=5,order_avg=1000)+'\\n\\n')\n",
    "print(queries.customer_orders(product_id=10,sdate='1-10-2022',edate=quicksql.NoStr(\"DATE'4-11-2023'\"),something_not_a_param='test')+'\\n\\n')\n",
    "print(queries.contributing_employees(num_orders=6)+'\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T18:31:25.545784200Z",
     "start_time": "2023-11-04T18:31:25.345791700Z"
    }
   },
   "id": "fd89cefce0d7bcf2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the first one returns the query string, the second returns while printing a warning with a notification of a variable not part of the query, and the third raises an error with a missing parameter.  \n",
    "For now only unordered but not optional `**kwargs` are supported. If it is worth implementing `*args` in the future, that can be added.  \n",
    "The parameters support any primitive type that can be converted into a string and collections of primitives eg tuples lists.  \n",
    "However the default treatment of a string is to wrap it in single quotes `' '`.  \n",
    "If we wanted to format our own SQL object and type reference then we can do that with `quicksql.NoStr`.  \n",
    "It's only function is to not add `' '` to the string in the query argument `__call__` method.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9afdbfa69bca7db"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "ARRAY[1, 2, 3, 4]::smallint[]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quicksql.NoStr(f'ARRAY{[1,2,3,4]}::smallint[]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:12:43.023304200Z",
     "start_time": "2023-11-04T19:12:43.018577600Z"
    }
   },
   "id": "6de959f1444239af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using PyQuickSQL's Session Transient Asset Cache\n",
    "This is a utility made to prevent redundant reloading of the same small to (relatively) large data assets from a remote location, and to provide multi-session permanence through your file system if that is desirable.  \n",
    "It works by caching the asset into a dictionary (default is `use_mem_cache=True`) and returning a copy, like functools @cache decorator.  \n",
    "If the memory cache fails it will fall back to the file system cache (always enabled hence the name `quicksql.file_cache`), and load the pickled asset.    \n",
    "If it can't find the pickled asset, it will lastly run the original function and save the asset to the enabled caches. \n",
    "To clear the cache you can call `quicksql.clear_cache(clr_mem=True, clr_file=True)`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8902c0dac3c410b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before importing quicksql you can change the default cache, either in your system's environment variables or like below.\n",
    "The default is `tempfile.gettempdir()`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac097766545d3e04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['QQ_CACHE_DIR']='path/to/cachedir'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "535274f79cd1079e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's test:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "593ef8cab8880b23"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import quicksql\n",
    "\n",
    "@quicksql.file_cache(use_mem_cache=True)\n",
    "def test_mem_cache(size:int):\n",
    "    return [randint(0,10) for _ in range(size)]\n",
    "\n",
    "\n",
    "def test_file_cache(size:int):\n",
    "    return [randint(0,10) for _ in range(size)]\n",
    "#if you want your IDE to retain the functions original argument names, this is an easy way:\n",
    "test_file_cache=quicksql.file_cache(use_mem_cache=False)(test_file_cache)\n",
    "\n",
    "def test_random(size:int):\n",
    "    return [randint(0,10) for _ in range(size)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T23:02:57.246944400Z",
     "start_time": "2023-11-05T23:02:57.230541100Z"
    }
   },
   "id": "386bdf6f11bff170"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4, 6, 6, 2, 7, 1, 0]\n",
      "[0, 0, 10, 0, 6, 0, 1, 3]\n",
      "[1, 6, 3, 9, 6, 6, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "print(test_mem_cache(8))\n",
    "print(test_file_cache(8))\n",
    "print(test_random(8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:51:35.837856600Z",
     "start_time": "2023-11-05T22:51:35.831326400Z"
    }
   },
   "id": "8acd391948661a27"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4, 6, 6, 2, 7, 1, 0]\n",
      "[0, 0, 10, 0, 6, 0, 1, 3]\n",
      "[8, 1, 1, 3, 2, 10, 10, 7]\n"
     ]
    }
   ],
   "source": [
    "print(test_mem_cache(8))\n",
    "print(test_file_cache(8))\n",
    "print(test_random(8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:51:37.607666600Z",
     "start_time": "2023-11-05T22:51:37.601788800Z"
    }
   },
   "id": "a03cd2ae1a6c1f5c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cache cleared.\n",
      "File cache cleared.\n",
      "[2, 7, 7, 2, 5, 10, 3, 0]\n",
      "[6, 2, 9, 9, 0, 8, 10, 7]\n",
      "[5, 5, 7, 7, 7, 1, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "quicksql.clear_cache(clr_mem=True,clr_file=True)\n",
    "print(test_mem_cache(8))\n",
    "print(test_file_cache(8))\n",
    "print(test_random(8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:51:46.208245800Z",
     "start_time": "2023-11-05T22:51:46.199698Z"
    }
   },
   "id": "af0b237504e93f45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's also possible to bootleg your own history by including descriptor arguments in your query function that aren't actually used in the query.  \n",
    "For a simple sql query I like to do this by defining `*args` and taking the last of the list as the actual query arg."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd2b554406ebea02"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test_memory(*sizes):\n",
    "    return [randint(0,10) for _ in range(sizes[-1])]\n",
    "test_memory=quicksql.file_cache(use_mem_cache=True)(test_memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:52:01.104723100Z",
     "start_time": "2023-11-05T22:52:01.099410800Z"
    }
   },
   "id": "3640cdb16273ae2c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4, 3, 4, 8, 0, 7, 4]\n",
      "[8, 9, 4, 2, 2, 5, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(test_memory('Yesterday',8))\n",
    "print(test_memory('Today','10:30',8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:52:02.951063900Z",
     "start_time": "2023-11-05T22:52:02.945360300Z"
    }
   },
   "id": "59b5e32c85b6ab55"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4, 3, 4, 8, 0, 7, 4]\n",
      "[8, 9, 4, 2, 2, 5, 3, 3]\n",
      "[0, 9, 6, 8, 10, 6, 7, 2]\n",
      "[0, 9, 6, 8, 10, 6, 7, 2]\n",
      "Memory cache cleared.\n",
      "File cache cleared.\n"
     ]
    }
   ],
   "source": [
    "print(test_memory('Yesterday',8))\n",
    "print(test_memory('Today','10:30',8))\n",
    "print(test_memory('Today','11:30',8))\n",
    "print(test_memory('Today','11:30',8))\n",
    "quicksql.clear_cache(clr_mem=True,clr_file=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:52:05.738781700Z",
     "start_time": "2023-11-05T22:52:05.733280400Z"
    }
   },
   "id": "3ca1087d2dc07661"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly async functions are supported."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a94aea1aba9537e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 9, 5, 8, 6, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "import asyncio as aio\n",
    "async def atest_memory(*sizes):\n",
    "    await aio.sleep(.01)\n",
    "    return [randint(0,10) for _ in range(sizes[-1])]\n",
    "atest_memory=quicksql.file_cache(use_mem_cache=True)(atest_memory)\n",
    "print(await atest_memory('Yesterday',8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T23:03:01.179239700Z",
     "start_time": "2023-11-05T23:03:01.158208300Z"
    }
   },
   "id": "50826cb48090bb27"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 9, 5, 8, 6, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "print(await atest_memory('Yesterday',8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T23:03:10.197933Z",
     "start_time": "2023-11-05T23:03:10.193394100Z"
    }
   },
   "id": "b65eac19609a9da2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Notes:\n",
    "The `file_cache` does not currently have great support for data management, you can save the pickled files yourself, change the cache directory, or add metadata as seen above. It would make sense to add a callable argument to specify the filetype and format of the saved asset, that could be implemented in the future.  \n",
    "Like functools `cache` is meant to reduce the cost of expensive calls, `file_cache` is meant to reduce the startup time for users with slow remote data connections for example when resetting a jupyter notebook or python env.  \n",
    "This is why there is only one function to clear the entire cache and `pickle` is used to support anything that might come out of a python function. Hence the example above might not be a good idea to use long term unless more functionality is added.  \n",
    "The key generation is more rudimentary than functools `cache` as well, consisting of the stringified args removing chars that won't write to a file's name.\n",
    "Features that might be helpful to add later:\n",
    "- An optional argument in `file_cache` that takes a callable which saves the data asset according to it's spec. eg, dataframe or ndarray -> parquet or csv file.\n",
    "- Specific cache deletions instead of deleting the entire thing (eg files or sub-directories).\n",
    "- Extended management of data asset snapshots, such as a separate directory to save permanent files, ability to switch to different directories either as an argument included in `file_cache`, system-wide change, or specific arguments in the wrapped function (or all of them). System-wide is already possible by changing `quicksql._quicksql.cache_dir` after importing, this will change where clear_cache is enacted as well.\n",
    "- The other reason to add a `file_cache` directory spec, would be connecting the same query to different data sources. That can also be handled using the method shown above.\n",
    "- The cache delete will fail if there are other directories in the cache, change if subdirectory/multidirectory management is added."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b3d1a3b88a0fcb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pyquicksql",
   "language": "python",
   "display_name": "Python (PyQuickSQL)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
