Metadata-Version: 2.1
Name: gguf-selector
Version: 0.0.5
Summary: GGUF selector
Author-email: calcuis <info@calcu.io>
Description-Content-Type: text/markdown
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Dist: llama-core >=0.1.2
Project-URL: Homepage, https://github.com/calcuis/gguf-selector
Project-URL: Issues, https://github.com/calcuis/gguf-selector/issues

### GGUF selector

[<img src="https://raw.githubusercontent.com/calcuis/gguf-selector/master/selector.gif" width="128" height="128">](https://github.com/calcuis/gguf-selector)
[![Static Badge](https://img.shields.io/badge/selector-0.0.5-pink?logo=github)](https://github.com/calcuis/gguf-selector/releases)

This package is a simple graphical user interface (GUI) application that uses the llama.cpp to interact with a chat model for generating responses.

#### include the module in your code
```
from gguf_selector import connector
```

You could pull any (pre-trained model) GGUF file(s) inside the folder and it will automatically be detected by the program.

[<img src="https://raw.githubusercontent.com/calcuis/chatgpt-model-selector/master/demo.gif" width="350" height="280">](https://github.com/calcuis/chatgpt-model-selector/blob/main/demo.gif)
[<img src="https://raw.githubusercontent.com/calcuis/chatgpt-model-selector/master/demo1.gif" width="350" height="280">](https://github.com/calcuis/chatgpt-model-selector/blob/main/demo1.gif)
