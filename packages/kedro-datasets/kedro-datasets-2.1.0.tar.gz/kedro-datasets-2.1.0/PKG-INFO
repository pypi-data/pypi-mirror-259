Metadata-Version: 2.1
Name: kedro-datasets
Version: 2.1.0
Summary: Kedro-Datasets is where you can find all of Kedro's data connectors.
Author: Kedro
License: Apache Software License (Apache 2.0)
Project-URL: Source, https://github.com/kedro-org/kedro-plugins/tree/main/kedro-datasets
Project-URL: Documentation, https://docs.kedro.org
Project-URL: Tracker, https://github.com/kedro-org/kedro-plugins/issues
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: kedro>=0.19
Requires-Dist: lazy_loader
Provides-Extra: api
Requires-Dist: requests~=2.20; extra == "api"
Provides-Extra: biosequence
Requires-Dist: biopython~=1.73; extra == "biosequence"
Provides-Extra: dask
Requires-Dist: dask[complete]>=2021.10; extra == "dask"
Requires-Dist: triad<1.0,>=0.6.7; extra == "dask"
Provides-Extra: databricks
Requires-Dist: delta-spark~=1.2.1; extra == "databricks"
Requires-Dist: pandas<3.0,>=1.3; extra == "databricks"
Requires-Dist: pyspark<4.0,>=2.2; extra == "databricks"
Provides-Extra: geopandas
Requires-Dist: geopandas<1.0,>=0.6.0; extra == "geopandas"
Requires-Dist: pyproj~=3.0; extra == "geopandas"
Provides-Extra: holoviews
Requires-Dist: holoviews~=1.13.0; extra == "holoviews"
Provides-Extra: huggingface
Requires-Dist: datasets; extra == "huggingface"
Requires-Dist: huggingface_hub; extra == "huggingface"
Requires-Dist: transformers; extra == "huggingface"
Provides-Extra: matlab
Requires-Dist: scipy; extra == "matlab"
Provides-Extra: matplotlib
Requires-Dist: matplotlib<4.0,>=3.0.3; extra == "matplotlib"
Provides-Extra: networkx
Requires-Dist: networkx~=2.4; extra == "networkx"
Provides-Extra: pandas
Requires-Dist: SQLAlchemy<3.0,>=1.4; extra == "pandas"
Requires-Dist: deltalake>=0.10.0; extra == "pandas"
Requires-Dist: lxml~=4.6; extra == "pandas"
Requires-Dist: openpyxl<4.0,>=3.0.6; extra == "pandas"
Requires-Dist: pandas-gbq<0.18.0,>=0.12.0; python_version < "3.11" and extra == "pandas"
Requires-Dist: pandas-gbq>=0.18.0; python_version >= "3.11" and extra == "pandas"
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas"
Requires-Dist: pyarrow>=6.0; extra == "pandas"
Requires-Dist: pyodbc~=4.0; extra == "pandas"
Requires-Dist: tables~=3.6; extra == "pandas"
Provides-Extra: pickle
Requires-Dist: compress-pickle[lz4]~=2.1.0; extra == "pickle"
Provides-Extra: pillow
Requires-Dist: Pillow~=9.0; extra == "pillow"
Provides-Extra: plotly
Requires-Dist: pandas<3.0,>=1.3; extra == "plotly"
Requires-Dist: plotly<6.0,>=4.8.0; extra == "plotly"
Provides-Extra: polars
Requires-Dist: deltalake>=0.6.2; extra == "polars"
Requires-Dist: polars>=0.18.0; extra == "polars"
Requires-Dist: pyarrow>=4.0; extra == "polars"
Requires-Dist: xlsx2csv>=0.8.0; extra == "polars"
Provides-Extra: redis
Requires-Dist: redis~=4.1; extra == "redis"
Provides-Extra: snowflake
Requires-Dist: snowflake-snowpark-python~=1.0; extra == "snowflake"
Provides-Extra: spark
Requires-Dist: delta-spark<3.0,>=1.0; extra == "spark"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "spark"
Requires-Dist: pyspark<4.0,>=2.2; extra == "spark"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "spark"
Provides-Extra: svmlight
Requires-Dist: scikit-learn>=1.0.2; extra == "svmlight"
Requires-Dist: scipy~=1.7.3; extra == "svmlight"
Provides-Extra: tensorflow
Requires-Dist: tensorflow-macos~=2.0; (platform_system == "Darwin" and platform_machine == "arm64") and extra == "tensorflow"
Requires-Dist: tensorflow~=2.0; (platform_system != "Darwin" or platform_machine != "arm64") and extra == "tensorflow"
Provides-Extra: video
Requires-Dist: opencv-python~=4.5.5.64; extra == "video"
Provides-Extra: yaml
Requires-Dist: PyYAML<7.0,>=4.2; extra == "yaml"
Requires-Dist: pandas<3.0,>=1.3; extra == "yaml"
Provides-Extra: api-apidataset
Requires-Dist: requests~=2.20; extra == "api-apidataset"
Provides-Extra: biosequence-biosequencedataset
Requires-Dist: biopython~=1.73; extra == "biosequence-biosequencedataset"
Provides-Extra: dask-parquetdataset
Requires-Dist: dask[complete]>=2021.10; extra == "dask-parquetdataset"
Requires-Dist: triad<1.0,>=0.6.7; extra == "dask-parquetdataset"
Provides-Extra: databricks-managedtabledataset
Requires-Dist: pyspark<4.0,>=2.2; extra == "databricks-managedtabledataset"
Requires-Dist: pandas<3.0,>=1.3; extra == "databricks-managedtabledataset"
Requires-Dist: delta-spark~=1.2.1; extra == "databricks-managedtabledataset"
Provides-Extra: geopandas-geojsondataset
Requires-Dist: geopandas<1.0,>=0.6.0; extra == "geopandas-geojsondataset"
Requires-Dist: pyproj~=3.0; extra == "geopandas-geojsondataset"
Provides-Extra: holoviews-holoviewswriter
Requires-Dist: holoviews~=1.13.0; extra == "holoviews-holoviewswriter"
Provides-Extra: matplotlib-matplotlibwriter
Requires-Dist: matplotlib<4.0,>=3.0.3; extra == "matplotlib-matplotlibwriter"
Provides-Extra: networkx-networkxdataset
Requires-Dist: networkx~=2.4; extra == "networkx-networkxdataset"
Provides-Extra: pandas-csvdataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-csvdataset"
Provides-Extra: pandas-exceldataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-exceldataset"
Requires-Dist: openpyxl<4.0,>=3.0.6; extra == "pandas-exceldataset"
Provides-Extra: pandas-deltatabledataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-deltatabledataset"
Requires-Dist: deltalake>=0.10.0; extra == "pandas-deltatabledataset"
Provides-Extra: pandas-featherdataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-featherdataset"
Provides-Extra: pandas-gbqtabledataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-gbqtabledataset"
Requires-Dist: pandas-gbq<0.18.0,>=0.12.0; python_version < "3.11" and extra == "pandas-gbqtabledataset"
Requires-Dist: pandas-gbq>=0.18.0; python_version >= "3.11" and extra == "pandas-gbqtabledataset"
Provides-Extra: pandas-gbqquerydataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-gbqquerydataset"
Requires-Dist: pandas-gbq<0.18.0,>=0.12.0; python_version < "3.11" and extra == "pandas-gbqquerydataset"
Requires-Dist: pandas-gbq>=0.18.0; python_version >= "3.11" and extra == "pandas-gbqquerydataset"
Provides-Extra: pandas-hdfdataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-hdfdataset"
Requires-Dist: tables~=3.6; extra == "pandas-hdfdataset"
Provides-Extra: pandas-jsondataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-jsondataset"
Provides-Extra: pandas-parquetdataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-parquetdataset"
Requires-Dist: pyarrow>=6.0; extra == "pandas-parquetdataset"
Provides-Extra: pandas-sqltabledataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-sqltabledataset"
Requires-Dist: SQLAlchemy<3.0,>=1.4; extra == "pandas-sqltabledataset"
Provides-Extra: pandas-sqlquerydataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-sqlquerydataset"
Requires-Dist: SQLAlchemy<3.0,>=1.4; extra == "pandas-sqlquerydataset"
Requires-Dist: pyodbc~=4.0; extra == "pandas-sqlquerydataset"
Provides-Extra: pandas-xmldataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-xmldataset"
Requires-Dist: lxml~=4.6; extra == "pandas-xmldataset"
Provides-Extra: pandas-genericdataset
Requires-Dist: pandas<3.0,>=1.3; extra == "pandas-genericdataset"
Provides-Extra: pickle-pickledataset
Requires-Dist: compress-pickle[lz4]~=2.1.0; extra == "pickle-pickledataset"
Provides-Extra: pillow-imagedataset
Requires-Dist: Pillow~=9.0; extra == "pillow-imagedataset"
Provides-Extra: plotly-plotlydataset
Requires-Dist: pandas<3.0,>=1.3; extra == "plotly-plotlydataset"
Requires-Dist: plotly<6.0,>=4.8.0; extra == "plotly-plotlydataset"
Provides-Extra: plotly-jsondataset
Requires-Dist: plotly<6.0,>=4.8.0; extra == "plotly-jsondataset"
Provides-Extra: polars-csvdataset
Requires-Dist: polars>=0.18.0; extra == "polars-csvdataset"
Provides-Extra: polars-genericdataset
Requires-Dist: polars>=0.18.0; extra == "polars-genericdataset"
Requires-Dist: pyarrow>=4.0; extra == "polars-genericdataset"
Requires-Dist: xlsx2csv>=0.8.0; extra == "polars-genericdataset"
Requires-Dist: deltalake>=0.6.2; extra == "polars-genericdataset"
Provides-Extra: polars-eagerpolarsdataset
Requires-Dist: polars>=0.18.0; extra == "polars-eagerpolarsdataset"
Requires-Dist: pyarrow>=4.0; extra == "polars-eagerpolarsdataset"
Requires-Dist: xlsx2csv>=0.8.0; extra == "polars-eagerpolarsdataset"
Requires-Dist: deltalake>=0.6.2; extra == "polars-eagerpolarsdataset"
Provides-Extra: polars-lazypolarsdataset
Requires-Dist: polars>=0.18.0; extra == "polars-lazypolarsdataset"
Requires-Dist: pyarrow>=4.0; extra == "polars-lazypolarsdataset"
Requires-Dist: deltalake>=0.6.2; extra == "polars-lazypolarsdataset"
Provides-Extra: snowflake-snowparktabledataset
Requires-Dist: snowflake-snowpark-python~=1.0; extra == "snowflake-snowparktabledataset"
Provides-Extra: spark-sparkdataset
Requires-Dist: pyspark<4.0,>=2.2; extra == "spark-sparkdataset"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "spark-sparkdataset"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "spark-sparkdataset"
Provides-Extra: spark-sparkhivedataset
Requires-Dist: pyspark<4.0,>=2.2; extra == "spark-sparkhivedataset"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "spark-sparkhivedataset"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "spark-sparkhivedataset"
Provides-Extra: spark-sparkjdbcdataset
Requires-Dist: pyspark<4.0,>=2.2; extra == "spark-sparkjdbcdataset"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "spark-sparkjdbcdataset"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "spark-sparkjdbcdataset"
Provides-Extra: spark-deltatabledataset
Requires-Dist: pyspark<4.0,>=2.2; extra == "spark-deltatabledataset"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "spark-deltatabledataset"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "spark-deltatabledataset"
Requires-Dist: delta-spark<3.0,>=1.0; extra == "spark-deltatabledataset"
Provides-Extra: svmlight-svmlightdataset
Requires-Dist: scikit-learn>=1.0.2; extra == "svmlight-svmlightdataset"
Requires-Dist: scipy~=1.7.3; extra == "svmlight-svmlightdataset"
Provides-Extra: tensorflow-tensorflowmodeldataset
Requires-Dist: tensorflow~=2.0; (platform_system != "Darwin" or platform_machine != "arm64") and extra == "tensorflow-tensorflowmodeldataset"
Requires-Dist: tensorflow-macos~=2.0; (platform_system == "Darwin" and platform_machine == "arm64") and extra == "tensorflow-tensorflowmodeldataset"
Provides-Extra: video-videodataset
Requires-Dist: opencv-python~=4.5.5.64; extra == "video-videodataset"
Provides-Extra: yaml-yamldataset
Requires-Dist: pandas<3.0,>=1.3; extra == "yaml-yamldataset"
Requires-Dist: PyYAML<7.0,>=4.2; extra == "yaml-yamldataset"
Provides-Extra: all
Requires-Dist: Pillow~=9.0; extra == "all"
Requires-Dist: PyYAML<7.0,>=4.2; extra == "all"
Requires-Dist: SQLAlchemy<3.0,>=1.4; extra == "all"
Requires-Dist: biopython~=1.73; extra == "all"
Requires-Dist: compress-pickle[lz4]~=2.1.0; extra == "all"
Requires-Dist: dask[complete]>=2021.10; extra == "all"
Requires-Dist: datasets; extra == "all"
Requires-Dist: delta-spark<3.0,>=1.0; extra == "all"
Requires-Dist: delta-spark~=1.2.1; extra == "all"
Requires-Dist: deltalake>=0.6.2; extra == "all"
Requires-Dist: deltalake>=0.10.0; extra == "all"
Requires-Dist: geopandas<1.0,>=0.6.0; extra == "all"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "all"
Requires-Dist: holoviews~=1.13.0; extra == "all"
Requires-Dist: huggingface_hub; extra == "all"
Requires-Dist: lxml~=4.6; extra == "all"
Requires-Dist: matplotlib<4.0,>=3.0.3; extra == "all"
Requires-Dist: networkx~=2.4; extra == "all"
Requires-Dist: opencv-python~=4.5.5.64; extra == "all"
Requires-Dist: openpyxl<4.0,>=3.0.6; extra == "all"
Requires-Dist: pandas-gbq<0.18.0,>=0.12.0; python_version < "3.11" and extra == "all"
Requires-Dist: pandas-gbq>=0.18.0; python_version >= "3.11" and extra == "all"
Requires-Dist: pandas<3.0,>=1.3; extra == "all"
Requires-Dist: plotly<6.0,>=4.8.0; extra == "all"
Requires-Dist: polars>=0.18.0; extra == "all"
Requires-Dist: pyarrow>=4.0; extra == "all"
Requires-Dist: pyarrow>=6.0; extra == "all"
Requires-Dist: pyodbc~=4.0; extra == "all"
Requires-Dist: pyproj~=3.0; extra == "all"
Requires-Dist: pyspark<4.0,>=2.2; extra == "all"
Requires-Dist: redis~=4.1; extra == "all"
Requires-Dist: requests~=2.20; extra == "all"
Requires-Dist: s3fs<2024.1,>=2021.4; extra == "all"
Requires-Dist: scikit-learn>=1.0.2; extra == "all"
Requires-Dist: scipy; extra == "all"
Requires-Dist: scipy~=1.7.3; extra == "all"
Requires-Dist: snowflake-snowpark-python~=1.0; extra == "all"
Requires-Dist: tables~=3.6; extra == "all"
Requires-Dist: tensorflow-macos~=2.0; (platform_system == "Darwin" and platform_machine == "arm64") and extra == "all"
Requires-Dist: tensorflow~=2.0; (platform_system != "Darwin" or platform_machine != "arm64") and extra == "all"
Requires-Dist: transformers; extra == "all"
Requires-Dist: triad<1.0,>=0.6.7; extra == "all"
Requires-Dist: xlsx2csv>=0.8.0; extra == "all"
Provides-Extra: docs
Requires-Dist: docutils==0.16; extra == "docs"
Requires-Dist: sphinx~=5.3.0; extra == "docs"
Requires-Dist: sphinx_rtd_theme==1.2.0; extra == "docs"
Requires-Dist: sphinx-autodoc-typehints==1.20.2; extra == "docs"
Requires-Dist: sphinx_copybutton==0.3.1; extra == "docs"
Requires-Dist: sphinx-notfound-page; extra == "docs"
Requires-Dist: ipykernel<7.0,>=5.3; extra == "docs"
Requires-Dist: sphinxcontrib-mermaid~=0.7.1; extra == "docs"
Requires-Dist: myst-parser~=1.0.0; extra == "docs"
Requires-Dist: Jinja2<3.1.0; extra == "docs"
Provides-Extra: test
Requires-Dist: adlfs~=2023.1; extra == "test"
Requires-Dist: bandit<2.0,>=1.6.2; extra == "test"
Requires-Dist: behave==1.2.6; extra == "test"
Requires-Dist: biopython~=1.73; extra == "test"
Requires-Dist: blacken-docs==1.9.2; extra == "test"
Requires-Dist: black~=22.0; extra == "test"
Requires-Dist: cloudpickle<=2.0.0; extra == "test"
Requires-Dist: compress-pickle[lz4]~=2.1.0; extra == "test"
Requires-Dist: coverage[toml]; extra == "test"
Requires-Dist: dask[complete]>=2021.10; extra == "test"
Requires-Dist: delta-spark<3.0,>=1.0; extra == "test"
Requires-Dist: deltalake<0.15.2,>=0.10.0; extra == "test"
Requires-Dist: dill~=0.3.1; extra == "test"
Requires-Dist: filelock<4.0,>=3.4.0; extra == "test"
Requires-Dist: gcsfs<2023.3,>=2023.1; extra == "test"
Requires-Dist: geopandas<1.0,>=0.6.0; extra == "test"
Requires-Dist: hdfs<3.0,>=2.5.8; extra == "test"
Requires-Dist: holoviews>=1.13.0; extra == "test"
Requires-Dist: import-linter[toml]==1.2.6; extra == "test"
Requires-Dist: ipython<8.0,>=7.31.1; extra == "test"
Requires-Dist: Jinja2<3.1.0; extra == "test"
Requires-Dist: joblib>=0.14; extra == "test"
Requires-Dist: jupyterlab~=3.0; extra == "test"
Requires-Dist: jupyter~=1.0; extra == "test"
Requires-Dist: lxml~=4.6; extra == "test"
Requires-Dist: matplotlib<3.4,>=3.0.3; python_version < "3.10" and extra == "test"
Requires-Dist: matplotlib<3.6,>=3.5; python_version >= "3.10" and extra == "test"
Requires-Dist: memory_profiler<1.0,>=0.50.0; extra == "test"
Requires-Dist: moto==5.0.0; extra == "test"
Requires-Dist: networkx~=2.4; extra == "test"
Requires-Dist: opencv-python~=4.5.5.64; extra == "test"
Requires-Dist: openpyxl<4.0,>=3.0.3; extra == "test"
Requires-Dist: pandas-gbq<0.18.0,>=0.12.0; python_version < "3.11" and extra == "test"
Requires-Dist: pandas-gbq>=0.18.0; python_version >= "3.11" and extra == "test"
Requires-Dist: pandas~=1.3; extra == "test"
Requires-Dist: Pillow~=9.0; extra == "test"
Requires-Dist: plotly<6.0,>=4.8.0; extra == "test"
Requires-Dist: polars[deltalake,xlsx2csv]~=0.18.0; extra == "test"
Requires-Dist: pre-commit>=2.9.2; extra == "test"
Requires-Dist: pyarrow>=1.0; python_version < "3.11" and extra == "test"
Requires-Dist: pyarrow>=7.0; python_version >= "3.11" and extra == "test"
Requires-Dist: pyodbc~=4.0.35; extra == "test"
Requires-Dist: pyproj~=3.0; extra == "test"
Requires-Dist: pyspark<3.4,>=2.2; python_version < "3.11" and extra == "test"
Requires-Dist: pyspark>=3.4; python_version >= "3.11" and extra == "test"
Requires-Dist: pytest-cov~=3.0; extra == "test"
Requires-Dist: pytest-mock<2.0,>=1.7.1; extra == "test"
Requires-Dist: pytest-xdist[psutil]~=2.2.1; extra == "test"
Requires-Dist: pytest~=7.2; extra == "test"
Requires-Dist: redis~=4.1; extra == "test"
Requires-Dist: requests-mock~=1.6; extra == "test"
Requires-Dist: requests~=2.20; extra == "test"
Requires-Dist: ruff~=0.0.290; extra == "test"
Requires-Dist: s3fs<2024.1,>=2021.04; extra == "test"
Requires-Dist: snowflake-snowpark-python~=1.0; python_version == "3.9" and extra == "test"
Requires-Dist: scikit-learn<2,>=1.0.2; extra == "test"
Requires-Dist: scipy>=1.7.3; extra == "test"
Requires-Dist: packaging; extra == "test"
Requires-Dist: SQLAlchemy~=1.2; extra == "test"
Requires-Dist: tables~=3.8.0; platform_system == "Windows" and extra == "test"
Requires-Dist: tables~=3.6; platform_system != "Windows" and extra == "test"
Requires-Dist: tensorflow-macos~=2.0; (platform_system == "Darwin" and platform_machine == "arm64") and extra == "test"
Requires-Dist: tensorflow~=2.0; (platform_system != "Darwin" or platform_machine != "arm64") and extra == "test"
Requires-Dist: triad<1.0,>=0.6.7; extra == "test"
Requires-Dist: trufflehog~=2.1; extra == "test"
Requires-Dist: xlsxwriter~=1.0; extra == "test"
Requires-Dist: datasets; extra == "test"
Requires-Dist: huggingface_hub; extra == "test"
Requires-Dist: transformers; extra == "test"

# Kedro-Datasets

<!-- Note that the contents of this file are also used in the documentation, see docs/source/index.md -->

[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python Version](https://img.shields.io/badge/python-3.9%20%7C%203.10%20%7C%203.11-blue.svg)](https://pypi.org/project/kedro-datasets/)
[![PyPI Version](https://badge.fury.io/py/kedro-datasets.svg)](https://pypi.org/project/kedro-datasets/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-black.svg)](https://github.com/ambv/black)

Welcome to `kedro_datasets`, the home of Kedro's data connectors. Here you will find `AbstractDataset` implementations powering Kedro's DataCatalog created by QuantumBlack and external contributors.

## Installation

`kedro-datasets` is a Python plugin. To install it:

```bash
pip install kedro-datasets
```

## What `AbstractDataset` implementations are supported?

We support a range of data connectors, including CSV, Excel, Parquet, Feather, HDF5, JSON, Pickle, SQL Tables, SQL Queries, Spark DataFrames and more. We even allow support for working with images.

These data connectors are supported with the APIs of `pandas`, `spark`, `networkx`, `matplotlib`, `yaml` and more.

[The Data Catalog](https://docs.kedro.org/en/stable/data/data_catalog.html) allows you to work with a range of file formats on local file systems, network file systems, cloud object stores, and Hadoop.

Here is a full list of [supported data connectors and APIs](https://docs.kedro.org/projects/kedro-datasets/en/kedro-datasets-2.0.0/api/kedro_datasets.html).

## How can I create my own `AbstractDataset` implementation?
Take a look at our [instructions on how to create your own `AbstractDataset` implementation](https://docs.kedro.org/en/stable/data/how_to_create_a_custom_dataset.html).

## Can I contribute?

Yes! Want to help build Kedro-Datasets? Check out our guide to [contributing](https://github.com/kedro-org/kedro-plugins/blob/main/kedro-datasets/CONTRIBUTING.md).

## What licence do you use?

Kedro-Datasets is licensed under the [Apache 2.0](https://github.com/kedro-org/kedro-plugins/blob/main/LICENSE.md) License.

## Python version support policy
* The [Kedro-Datasets](https://github.com/kedro-org/kedro-plugins/tree/main/kedro-datasets) package follows the [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) Python version support policy.
