{
    "name": "HF llama2 7b chat",
    "url": "https://bauzn496g1fv9lv0.us-east-1.aws.endpoints.huggingface.cloud",
    "token_name": "HF_INFERENCE_TOKEN",
    "prompt_handler": {
        "inputs": "<s>[INST] <<SYS>> You are a helpful assistant. You keep your answers short. <</SYS>> $PROMPT [/INST]",
        "parameters": {
            "max_new_tokens": 500
        }
    },
    "output_handler": "def parse(response): return response.json()[0][\"generated_text\"]"
}