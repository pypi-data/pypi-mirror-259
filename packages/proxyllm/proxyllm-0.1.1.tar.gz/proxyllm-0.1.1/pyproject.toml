[tool.poetry]
name = "proxyllm"
version = "0.1.1"
description = "LLM Proxy to reduce cost and complexity of using multiple LLMs"
authors = []
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
python-dotenv = "^1.0.0"
cohere = "^4.27"
tiktoken = "^0.5.1"
tokenizers = "^0.14.1"
transformers = {extras = ["torch"], version = "^4.35.2"}
torch = "^2.1.0"
google-cloud-aiplatform = "^1.35.0"
pyyaml = "^6.0.1"
datasets = "^2.14.7"
evaluate = "^0.4.1"
openai = "^1.11.1"

[tool.poetry.group.dev.dependencies]
black = "^23.9.1"
isort = "^5.13.2"

[tool.poetry.group.test.dependencies]
pytest = "^7.4.2"
coverage = "^7.3.2"

[tool.pytest.ini_options]
# filterwarnings = ["ignore::DeprecationWarning"]
testpaths = [
    "llmproxy/tests/unit_tests",
    "llmproxy/tests/integration_tests"
]

pythonpath = ["."]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
