 <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"> 
<html lang="en">
<head>
<title>
YOLOLogic-2.1.4.html
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body bgcolor="#f0f0f8">
<table width="100%" cellspacing="0" cellpadding="2" border="0" summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>YOLOLogic</strong></big></big> (version 2.1.4, 2024-February-28)</font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial">
</font></td></tr></table>
<p><a href="#YOLOLogic"><tt>YOLOLogic</tt></a>.py<br>
<tt>
&nbsp;<br>
Version:&nbsp;2.1.4<br>
&nbsp;&nbsp;&nbsp;<br>
Author:&nbsp;Avinash&nbsp;Kak&nbsp;(kak@purdue.edu)<br>
&nbsp;<br>
Date:&nbsp;2024-February-28<br>
&nbsp;<br>
&nbsp;<br>
</tt>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="2"> 
<TR>
<TH ALIGN=left>
<tt>
<b>Download Version 2.1.4:</b>&nbsp;  
<a HREF="https://engineering.purdue.edu/kak/distYOLO/YOLOLogic-2.1.4.tar.gz?download">gztar</a> 
&nbsp;             
<br>
<br>
&nbsp;
</tt>
</TH>
<TD>
<tt>
&nbsp;&nbsp;&nbsp;&nbsp;
Total number of downloads (all versions): 
<?php   
    $file = fopen("HowManyCounts.txt", "r") or exit("Unable to open file!");
    echo fgets($file);
    fclose($file);
?>
</tt>
<br>
<center>
<tt>
<font color="red" size="-2">
&nbsp;&nbsp;&nbsp;&nbsp;
This count is automatically updated at every rotation of
<br> 
&nbsp;&nbsp;&nbsp;&nbsp;
the weblogs (normally once every two to four days)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;
Last updated:
<?php   
    $file = fopen("LastUpdated.txt", "r") or exit("Unable to open file!");
    echo fgets($file);
    fclose($file);
?>
</font>
</tt>
</center>
</TD>
</TR>
</TABLE>
<br>
<tt>
<a HREF="YOLOLogic-2.1.4_CodeOnly.html">View the main module code file in your browser</a> 
&nbsp;<br>
&nbsp;<br>
<a HREF="datasets_for_YOLO.tar.gz">Download the image datasets for YOLO</a>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>   
&nbsp;<br>
<font size="+2" color="red">CHANGES:<br>
</font>
<br>

&nbsp;&nbsp;Version&nbsp;2.1.4:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;includes&nbsp;a&nbsp;bugfix&nbsp;in&nbsp;the&nbsp;testing&nbsp;routine&nbsp;for&nbsp;single-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection.&nbsp;&nbsp;The&nbsp;bug,&nbsp;in&nbsp;the&nbsp;function&nbsp;run_code_for_testing_single_<br>
&nbsp;&nbsp;&nbsp;&nbsp;instance_detector(model),&nbsp;was&nbsp;caused&nbsp;by&nbsp;my&nbsp;inadvertently&nbsp;changing&nbsp;the&nbsp;name&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;called&nbsp;function&nbsp;after&nbsp;I&nbsp;had&nbsp;finalized&nbsp;the&nbsp;code&nbsp;for&nbsp;distribution.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.1.3:&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;contains&nbsp;significantly&nbsp;improved&nbsp;documentation&nbsp;about&nbsp;how&nbsp;exactly<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;install&nbsp;the&nbsp;datasets&nbsp;needed&nbsp;by&nbsp;the&nbsp;two&nbsp;scripts&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;YOLOLogic&nbsp;module.&nbsp;&nbsp;Installing&nbsp;these&nbsp;datasets&nbsp;is&nbsp;a&nbsp;bit&nbsp;confusing&nbsp;because<br>
&nbsp;&nbsp;&nbsp;&nbsp;you&nbsp;have&nbsp;to&nbsp;go&nbsp;through&nbsp;two&nbsp;rounds&nbsp;of&nbsp;unpacking&nbsp;the&nbsp;top-level&nbsp;gzipped&nbsp;archive.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;top-level&nbsp;archive&nbsp;packs&nbsp;multiple&nbsp;gzipped&nbsp;archives&nbsp;for&nbsp;the&nbsp;individual<br>
&nbsp;&nbsp;&nbsp;&nbsp;single-instance&nbsp;and&nbsp;multi-instance&nbsp;cases.&nbsp;&nbsp;The&nbsp;improved&nbsp;documentation&nbsp;is&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;section&nbsp;"THE&nbsp;DATASETS&nbsp;YOU&nbsp;NEED&nbsp;TO&nbsp;USE"&nbsp;on&nbsp;this&nbsp;page.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.1.2:&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Replaced&nbsp;the&nbsp;older&nbsp;SkipBlock&nbsp;with&nbsp;the&nbsp;latest&nbsp;version&nbsp;from&nbsp;the&nbsp;DLStudio<br>
&nbsp;&nbsp;&nbsp;&nbsp;platform.&nbsp;&nbsp;The&nbsp;previous&nbsp;version&nbsp;was&nbsp;also&nbsp;throwing&nbsp;up&nbsp;run-time&nbsp;errors.&nbsp;&nbsp;That<br>
&nbsp;&nbsp;&nbsp;&nbsp;should&nbsp;not&nbsp;be&nbsp;the&nbsp;case&nbsp;with&nbsp;the&nbsp;new&nbsp;version.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.1.1:&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;With&nbsp;this&nbsp;version,&nbsp;what&nbsp;was&nbsp;previously&nbsp;the&nbsp;RegionProposalGenerator&nbsp;module&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;now&nbsp;the&nbsp;YOLOLogic&nbsp;module.&nbsp;This&nbsp;name&nbsp;change&nbsp;reflects&nbsp;the&nbsp;fact&nbsp;that&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;educational&nbsp;purpose&nbsp;of&nbsp;the&nbsp;module&nbsp;has&nbsp;shifted&nbsp;from&nbsp;constructing&nbsp;region<br>
&nbsp;&nbsp;&nbsp;&nbsp;proposal&nbsp;networks&nbsp;to&nbsp;carrying&nbsp;out&nbsp;multi-instance&nbsp;object&nbsp;detection&nbsp;in&nbsp;images<br>
&nbsp;&nbsp;&nbsp;&nbsp;using&nbsp;the&nbsp;YOLO&nbsp;logic.&nbsp;&nbsp;This&nbsp;change&nbsp;in&nbsp;the&nbsp;primary&nbsp;focus&nbsp;of&nbsp;the&nbsp;module&nbsp;has<br>
&nbsp;&nbsp;&nbsp;&nbsp;entailed&nbsp;reorganizing&nbsp;the&nbsp;code&nbsp;base.&nbsp;&nbsp;I&nbsp;have&nbsp;moved&nbsp;some&nbsp;of&nbsp;the&nbsp;code&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;main&nbsp;YOLOLogic&nbsp;class&nbsp;to&nbsp;the&nbsp;inner&nbsp;class&nbsp;RPN.&nbsp;&nbsp;The&nbsp;old&nbsp;region-proposal&nbsp;demos<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;still&nbsp;available&nbsp;through&nbsp;the&nbsp;RPN&nbsp;inner&nbsp;class.&nbsp;&nbsp;All&nbsp;the&nbsp;YOLO&nbsp;based<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi-object&nbsp;detection&nbsp;code&nbsp;is&nbsp;demoed&nbsp;by&nbsp;the&nbsp;script<br>
&nbsp;&nbsp;&nbsp;&nbsp;'multi_instance_object_detection.py'&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;distribution.&nbsp;&nbsp;And&nbsp;all&nbsp;the&nbsp;region-proposal&nbsp;code&nbsp;is&nbsp;demoed&nbsp;by&nbsp;the&nbsp;scripts&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;ExamplesRegionProposals&nbsp;subdirectory&nbsp;of&nbsp;the&nbsp;distribution.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.1.0:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;With&nbsp;this&nbsp;version,&nbsp;you&nbsp;can&nbsp;now&nbsp;use&nbsp;batches&nbsp;of&nbsp;any&nbsp;size&nbsp;for&nbsp;YOLO&nbsp;learning.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Previously,&nbsp;the&nbsp;batch&nbsp;size&nbsp;was&nbsp;limited&nbsp;to&nbsp;1&nbsp;for&nbsp;the&nbsp;YOLO&nbsp;part&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Allowing&nbsp;for&nbsp;batches&nbsp;required&nbsp;changes&nbsp;in&nbsp;the&nbsp;handling&nbsp;of&nbsp;problem&nbsp;images,&nbsp;such<br>
&nbsp;&nbsp;&nbsp;&nbsp;as&nbsp;the&nbsp;images&nbsp;with&nbsp;no&nbsp;meaningful&nbsp;objects,&nbsp;or&nbsp;the&nbsp;images&nbsp;with&nbsp;object&nbsp;bounding<br>
&nbsp;&nbsp;&nbsp;&nbsp;boxes&nbsp;with&nbsp;unrealistic&nbsp;aspect&nbsp;ratios.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.0.8:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;constitutes&nbsp;a&nbsp;complete&nbsp;implementation&nbsp;of&nbsp;a&nbsp;YOLO&nbsp;multi-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detector.&nbsp;&nbsp;In&nbsp;addition&nbsp;to&nbsp;the&nbsp;new&nbsp;multi-loss&nbsp;function&nbsp;that&nbsp;I&nbsp;introduced<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;previous&nbsp;public&nbsp;release&nbsp;of&nbsp;this&nbsp;module,&nbsp;the&nbsp;new&nbsp;version&nbsp;includes&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;full-blown&nbsp;implementation&nbsp;of&nbsp;what&nbsp;you&nbsp;need&nbsp;for&nbsp;validation&nbsp;testing.&nbsp;&nbsp;I&nbsp;should<br>
&nbsp;&nbsp;&nbsp;&nbsp;also&nbsp;mention&nbsp;that&nbsp;I&nbsp;have&nbsp;split&nbsp;what&nbsp;used&nbsp;to&nbsp;be&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;distribution&nbsp;into&nbsp;two&nbsp;directories:&nbsp;Examples&nbsp;and&nbsp;ExamplesRegionProposals.&nbsp;&nbsp;Your<br>
&nbsp;&nbsp;&nbsp;&nbsp;entry&nbsp;point&nbsp;for&nbsp;learning&nbsp;the&nbsp;YOLO&nbsp;implementation&nbsp;would&nbsp;be&nbsp;the&nbsp;script<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi_instance_object_detection.py&nbsp;in&nbsp;the&nbsp;directory&nbsp;Examples.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.0.6:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;incorporates&nbsp;a&nbsp;more&nbsp;sophisticated&nbsp;loss&nbsp;function&nbsp;for&nbsp;YOLO-based<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi-instance&nbsp;object&nbsp;detection&nbsp;in&nbsp;images.&nbsp;&nbsp;In&nbsp;the&nbsp;new&nbsp;loss&nbsp;function,&nbsp;I&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;criteria&nbsp;for&nbsp;the&nbsp;different&nbsp;segments&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;vector.&nbsp;&nbsp;[Assigning<br>
&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;object&nbsp;instance&nbsp;in&nbsp;a&nbsp;training&nbsp;image&nbsp;to&nbsp;an&nbsp;anchor&nbsp;box&nbsp;for&nbsp;a&nbsp;cell&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;involves&nbsp;creating&nbsp;a&nbsp;"5+C"-element&nbsp;YOLO&nbsp;vector,&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;classes.]&nbsp;I&nbsp;now&nbsp;use&nbsp;the&nbsp;Binary&nbsp;Cross-Entropy&nbsp;Loss&nbsp;(nn.BCELoss)&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;element&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;vector&nbsp;that&nbsp;stands&nbsp;for&nbsp;the&nbsp;presence&nbsp;or&nbsp;the&nbsp;absence<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;an&nbsp;object&nbsp;instance&nbsp;in&nbsp;a&nbsp;specific&nbsp;anchor&nbsp;box&nbsp;in&nbsp;a&nbsp;specific&nbsp;cell.&nbsp;&nbsp;I&nbsp;use<br>
&nbsp;&nbsp;&nbsp;&nbsp;mean-squared-error&nbsp;loss&nbsp;(nn.MSELoss)&nbsp;for&nbsp;the&nbsp;next&nbsp;four&nbsp;numerical&nbsp;elements&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;express&nbsp;the&nbsp;precise&nbsp;location&nbsp;of&nbsp;the&nbsp;object&nbsp;bounding-box&nbsp;vis-a-vis&nbsp;the&nbsp;center<br>
&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;cell&nbsp;to&nbsp;which&nbsp;the&nbsp;object&nbsp;is&nbsp;assigned&nbsp;and&nbsp;also&nbsp;for&nbsp;the&nbsp;dimensions&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;bounding&nbsp;box.&nbsp;&nbsp;Finally,&nbsp;I&nbsp;use&nbsp;the&nbsp;regular&nbsp;Cross-Entropy&nbsp;loss<br>
&nbsp;&nbsp;&nbsp;&nbsp;(nn.CrossEntropyLoss)&nbsp;for&nbsp;the&nbsp;last&nbsp;C&nbsp;elements&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;vector.&nbsp;&nbsp;Using&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;cross-entropy&nbsp;loss&nbsp;for&nbsp;the&nbsp;labeling&nbsp;errors&nbsp;required&nbsp;augmenting&nbsp;the&nbsp;YOLO&nbsp;vector<br>
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;one&nbsp;additional&nbsp;element&nbsp;to&nbsp;express&nbsp;the&nbsp;absence&nbsp;of&nbsp;an&nbsp;object.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.0.2:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;version&nbsp;fixes&nbsp;a&nbsp;couple&nbsp;of&nbsp;bugs&nbsp;in&nbsp;the&nbsp;YOLO-based&nbsp;logic&nbsp;for&nbsp;multi-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;2.0.1:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;module&nbsp;has&nbsp;gone&nbsp;through&nbsp;several&nbsp;changes&nbsp;since&nbsp;its&nbsp;last&nbsp;public-release<br>
&nbsp;&nbsp;&nbsp;&nbsp;version&nbsp;as&nbsp;I&nbsp;was&nbsp;experimenting&nbsp;with&nbsp;different&nbsp;ways&nbsp;of&nbsp;imparting&nbsp;to&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;students&nbsp;the&nbsp;sudden&nbsp;increase&nbsp;in&nbsp;model&nbsp;complexity&nbsp;as&nbsp;one&nbsp;goes&nbsp;from<br>
&nbsp;&nbsp;&nbsp;&nbsp;single-instance&nbsp;object&nbsp;detection&nbsp;to&nbsp;multi-instance&nbsp;object&nbsp;detection.&nbsp;&nbsp;These<br>
&nbsp;&nbsp;&nbsp;&nbsp;experiments&nbsp;led&nbsp;to&nbsp;the&nbsp;creation&nbsp;of&nbsp;two&nbsp;new&nbsp;datasets,&nbsp;PurdueDrEvalDataset&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;PurdueDrEvalMultiDataset,&nbsp;the&nbsp;former&nbsp;for&nbsp;playing&nbsp;with&nbsp;single-instance&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;detection&nbsp;and&nbsp;the&nbsp;latter&nbsp;for&nbsp;doing&nbsp;the&nbsp;same&nbsp;with&nbsp;multi-instance&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;detection.&nbsp;&nbsp;The&nbsp;module&nbsp;also&nbsp;includes&nbsp;two&nbsp;inner&nbsp;classes,&nbsp;SingleInstanceDetector<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;YoloObjectDetector,&nbsp;the&nbsp;former&nbsp;a&nbsp;reference&nbsp;implementation&nbsp;for&nbsp;single<br>
&nbsp;&nbsp;&nbsp;&nbsp;instance&nbsp;object&nbsp;detection&nbsp;and&nbsp;the&nbsp;latter&nbsp;a&nbsp;YOLO&nbsp;reference&nbsp;implementation&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;multi-instance&nbsp;object&nbsp;detection.&nbsp;[By&nbsp;the&nbsp;way,&nbsp;"DrEval"&nbsp;in&nbsp;the&nbsp;names&nbsp;of&nbsp;the&nbsp;two<br>
&nbsp;&nbsp;&nbsp;&nbsp;datasets&nbsp;mentioned&nbsp;here&nbsp;has&nbsp;a&nbsp;connection&nbsp;with&nbsp;"Dr&nbsp;Evil"&nbsp;in&nbsp;the&nbsp;Austin&nbsp;Powers<br>
&nbsp;&nbsp;&nbsp;&nbsp;movies.]<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.0.5:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;In&nbsp;keeping&nbsp;with&nbsp;the&nbsp;tutorial&nbsp;nature&nbsp;of&nbsp;this&nbsp;module,&nbsp;this&nbsp;version&nbsp;includes<br>
&nbsp;&nbsp;&nbsp;&nbsp;methods&nbsp;that&nbsp;come&nbsp;in&nbsp;handy&nbsp;for&nbsp;batch-based&nbsp;processing&nbsp;of&nbsp;images.&nbsp;These&nbsp;methods<br>
&nbsp;&nbsp;&nbsp;&nbsp;carry&nbsp;names&nbsp;like&nbsp;"displaying_and_histogramming_&nbsp;images_in_batchX()"&nbsp;where&nbsp;X&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3.&nbsp;&nbsp;The&nbsp;rest&nbsp;of&nbsp;the&nbsp;module,&nbsp;especially&nbsp;the&nbsp;part&nbsp;that&nbsp;deals&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;constructing&nbsp;region&nbsp;proposals&nbsp;remains&nbsp;unchanged.<br>
&nbsp;<br>
&nbsp;&nbsp;Version&nbsp;1.0.4:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;the&nbsp;first&nbsp;public&nbsp;release&nbsp;version&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">INTRODUCTION:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Single-Instance&nbsp;vs.&nbsp;Multi-Instance&nbsp;Detection:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;module&nbsp;was&nbsp;created&nbsp;for&nbsp;experimenting&nbsp;with&nbsp;the&nbsp;logic&nbsp;of&nbsp;object&nbsp;detection<br>
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;neural&nbsp;networks.&nbsp;&nbsp;On&nbsp;the&nbsp;face&nbsp;of&nbsp;it,&nbsp;object&nbsp;detection&nbsp;in&nbsp;images&nbsp;sounds<br>
&nbsp;&nbsp;&nbsp;&nbsp;like&nbsp;a&nbsp;well-defined&nbsp;problem&nbsp;that&nbsp;should&nbsp;lend&nbsp;itself&nbsp;to&nbsp;well-defined&nbsp;solutions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Unfortunately,&nbsp;the&nbsp;reality&nbsp;is&nbsp;otherwise.&nbsp;&nbsp;Yes,&nbsp;simple&nbsp;examples&nbsp;of&nbsp;the&nbsp;problem<br>
&nbsp;&nbsp;&nbsp;&nbsp;--&nbsp;such&nbsp;as&nbsp;when&nbsp;the&nbsp;images&nbsp;contain&nbsp;single&nbsp;object&nbsp;instances&nbsp;and&nbsp;with&nbsp;no<br>
&nbsp;&nbsp;&nbsp;&nbsp;competing&nbsp;clutter&nbsp;in&nbsp;the&nbsp;background&nbsp;--&nbsp;the&nbsp;problem&nbsp;can&nbsp;be&nbsp;solved<br>
&nbsp;&nbsp;&nbsp;&nbsp;straightforwardly&nbsp;with&nbsp;a&nbsp;neural&nbsp;network.&nbsp;&nbsp;However,&nbsp;the&nbsp;object&nbsp;detection<br>
&nbsp;&nbsp;&nbsp;&nbsp;problems&nbsp;that&nbsp;are&nbsp;encountered&nbsp;in&nbsp;real&nbsp;life&nbsp;are&nbsp;rarely&nbsp;that&nbsp;simple.&nbsp;&nbsp;A<br>
&nbsp;&nbsp;&nbsp;&nbsp;practically&nbsp;useful&nbsp;framework&nbsp;for&nbsp;object&nbsp;detection&nbsp;must&nbsp;be&nbsp;able&nbsp;to&nbsp;recognize<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;localize&nbsp;all&nbsp;possible&nbsp;instances&nbsp;of&nbsp;the&nbsp;objects&nbsp;of&nbsp;interest&nbsp;in&nbsp;a&nbsp;given<br>
&nbsp;&nbsp;&nbsp;&nbsp;image.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;So&nbsp;how&nbsp;does&nbsp;one&nbsp;solve&nbsp;the&nbsp;problem&nbsp;of&nbsp;multi-instance&nbsp;object&nbsp;detection&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;localization&nbsp;with&nbsp;a&nbsp;neural&nbsp;network?<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;last&nbsp;half-dozen&nbsp;years&nbsp;have&nbsp;seen&nbsp;the&nbsp;emergence&nbsp;of&nbsp;the&nbsp;following&nbsp;three<br>
&nbsp;&nbsp;&nbsp;&nbsp;competition-grade&nbsp;neural-network&nbsp;based&nbsp;approaches&nbsp;for&nbsp;multi-instance&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;detection:&nbsp;R-CNN,&nbsp;YOLO,&nbsp;and&nbsp;SSD.&nbsp;&nbsp;The&nbsp;Preamble&nbsp;section&nbsp;of&nbsp;my&nbsp;Week&nbsp;8&nbsp;lecture<br>
&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;Purdue's&nbsp;Deep&nbsp;Learning&nbsp;class&nbsp;provides&nbsp;a&nbsp;brief&nbsp;overview&nbsp;of&nbsp;these<br>
&nbsp;&nbsp;&nbsp;&nbsp;approaches.&nbsp;&nbsp;YOLO&nbsp;stands&nbsp;for&nbsp;"You&nbsp;Only&nbsp;Look&nbsp;Once"&nbsp;---&nbsp;in&nbsp;contrast&nbsp;with&nbsp;R-CNN<br>
&nbsp;&nbsp;&nbsp;&nbsp;based&nbsp;approaches&nbsp;in&nbsp;which&nbsp;you&nbsp;may&nbsp;have&nbsp;to&nbsp;subject&nbsp;the&nbsp;images&nbsp;to&nbsp;a&nbsp;couple&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;neural&nbsp;networks,&nbsp;one&nbsp;for&nbsp;generating&nbsp;region&nbsp;proposals&nbsp;and&nbsp;the&nbsp;other&nbsp;for&nbsp;actual<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;main&nbsp;goal&nbsp;of&nbsp;the&nbsp;present&nbsp;module&nbsp;is&nbsp;to&nbsp;provide&nbsp;an&nbsp;educational&nbsp;example&nbsp;of&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;complete&nbsp;implementation&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;logic&nbsp;for&nbsp;multi-instance&nbsp;object&nbsp;detection<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;images.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Graph-Based&nbsp;Algorithms&nbsp;for&nbsp;Region&nbsp;Proposals:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;second&nbsp;goal&nbsp;of&nbsp;this&nbsp;module&nbsp;is&nbsp;to&nbsp;provide&nbsp;implementations&nbsp;for&nbsp;a&nbsp;couple&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;more&nbsp;modern&nbsp;graph-based&nbsp;approaches&nbsp;for&nbsp;generating&nbsp;region&nbsp;proposals.&nbsp;&nbsp;At&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;point,&nbsp;the&nbsp;reader&nbsp;might&nbsp;ask:&nbsp;What&nbsp;is&nbsp;a&nbsp;region&nbsp;proposal?&nbsp;&nbsp;A&nbsp;region&nbsp;proposal&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;blob&nbsp;of&nbsp;pixels&nbsp;that&nbsp;is&nbsp;highly&nbsp;likely&nbsp;to&nbsp;contain&nbsp;an&nbsp;object&nbsp;instance.&nbsp;&nbsp;Another<br>
&nbsp;&nbsp;&nbsp;&nbsp;way&nbsp;of&nbsp;saying&nbsp;same&nbsp;thing&nbsp;is&nbsp;that&nbsp;region&nbsp;proposals&nbsp;are&nbsp;pixel&nbsp;blobs&nbsp;that&nbsp;look<br>
&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;from&nbsp;the&nbsp;general&nbsp;background&nbsp;in&nbsp;the&nbsp;images.&nbsp;&nbsp;While&nbsp;it&nbsp;is&nbsp;possible&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;use&nbsp;a&nbsp;neural&nbsp;network&nbsp;for&nbsp;generating&nbsp;region&nbsp;proposals,&nbsp;as&nbsp;demonstrated&nbsp;by&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;success&nbsp;of&nbsp;RPN&nbsp;(Region&nbsp;Proposal&nbsp;Network)&nbsp;in&nbsp;the&nbsp;R-CNN&nbsp;based&nbsp;multi-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection,&nbsp;the&nbsp;YOLOLogic&nbsp;module&nbsp;is&nbsp;concerned&nbsp;primarily&nbsp;with&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;non-neural-network&nbsp;based&nbsp;methods&nbsp;--&nbsp;the&nbsp;graph-based&nbsp;methods&nbsp;--&nbsp;for&nbsp;generating<br>
&nbsp;&nbsp;&nbsp;&nbsp;region&nbsp;proposals.&nbsp;&nbsp;I&nbsp;believe&nbsp;that&nbsp;becoming&nbsp;familiar&nbsp;with&nbsp;the&nbsp;non-learning<br>
&nbsp;&nbsp;&nbsp;&nbsp;based&nbsp;methods&nbsp;for&nbsp;constructing&nbsp;region&nbsp;proposals&nbsp;still&nbsp;has&nbsp;considerable&nbsp;value.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Consider,&nbsp;for&nbsp;example,&nbsp;the&nbsp;problem&nbsp;of&nbsp;detecting&nbsp;objects&nbsp;in&nbsp;satellite&nbsp;images<br>
&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;you&nbsp;simply&nbsp;do&nbsp;not&nbsp;have&nbsp;access&nbsp;to&nbsp;the&nbsp;amount&nbsp;of&nbsp;training&nbsp;data&nbsp;you&nbsp;would<br>
&nbsp;&nbsp;&nbsp;&nbsp;need&nbsp;for&nbsp;a&nbsp;neural-network&nbsp;based&nbsp;approach&nbsp;to&nbsp;work.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;With&nbsp;regard&nbsp;to&nbsp;the&nbsp;graph-based&nbsp;method&nbsp;for&nbsp;generating&nbsp;region&nbsp;proposals,<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;implements&nbsp;elements&nbsp;of&nbsp;the&nbsp;Selective&nbsp;Search&nbsp;(SS)&nbsp;algorithm&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection&nbsp;as&nbsp;proposed&nbsp;by&nbsp;Uijlings,&nbsp;van&nbsp;de&nbsp;Sande,&nbsp;Gevers,&nbsp;and&nbsp;Smeulders.<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;Selective&nbsp;Search&nbsp;algorithm&nbsp;sits&nbsp;on&nbsp;top&nbsp;of&nbsp;the&nbsp;graph-based&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;segmentation&nbsp;algorithm&nbsp;of&nbsp;Felzenszwalb&nbsp;and&nbsp;Huttenlocher&nbsp;(FH)&nbsp;whose<br>
&nbsp;&nbsp;&nbsp;&nbsp;implementation&nbsp;is&nbsp;also&nbsp;included&nbsp;in&nbsp;the&nbsp;YOLOLogic&nbsp;module.&nbsp;&nbsp;The&nbsp;YOLOLogic&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;processes&nbsp;an&nbsp;image&nbsp;with&nbsp;the&nbsp;FH&nbsp;graph-based&nbsp;algorithm&nbsp;for&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;segmentation&nbsp;to&nbsp;divide&nbsp;an&nbsp;image&nbsp;into&nbsp;pixel&nbsp;blobs.&nbsp;&nbsp;The&nbsp;module&nbsp;subsequently<br>
&nbsp;&nbsp;&nbsp;&nbsp;invokes&nbsp;elements&nbsp;of&nbsp;the&nbsp;SS&nbsp;algorithm&nbsp;to&nbsp;selectively&nbsp;merge&nbsp;the&nbsp;blobs&nbsp;on&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;basis&nbsp;of&nbsp;three&nbsp;properties:&nbsp;homogeneity&nbsp;of&nbsp;the&nbsp;color,&nbsp;grayscale&nbsp;variance,&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;texture&nbsp;homogeneity.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;FH&nbsp;algorithm&nbsp;is&nbsp;based&nbsp;on&nbsp;creating&nbsp;a&nbsp;graph-based&nbsp;representation&nbsp;of&nbsp;an&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;which,&nbsp;at&nbsp;the&nbsp;beginning,&nbsp;each&nbsp;pixel&nbsp;is&nbsp;a&nbsp;single&nbsp;vertex&nbsp;and&nbsp;the&nbsp;edge&nbsp;between<br>
&nbsp;&nbsp;&nbsp;&nbsp;two&nbsp;vertices&nbsp;that&nbsp;stand&nbsp;for&nbsp;two&nbsp;adjacent&nbsp;pixels&nbsp;represents&nbsp;the&nbsp;difference<br>
&nbsp;&nbsp;&nbsp;&nbsp;between&nbsp;some&nbsp;pixel&nbsp;property&nbsp;(such&nbsp;as&nbsp;the&nbsp;color&nbsp;difference)&nbsp;at&nbsp;the&nbsp;two&nbsp;pixels.<br>
&nbsp;&nbsp;&nbsp;&nbsp;Subsequently,&nbsp;for&nbsp;the&nbsp;vertex&nbsp;merging&nbsp;logic,&nbsp;each&nbsp;vertex&nbsp;u,&nbsp;that&nbsp;after&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;iteration&nbsp;stands&nbsp;for&nbsp;a&nbsp;grouping&nbsp;of&nbsp;pixels,&nbsp;is&nbsp;characterized&nbsp;by&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;property&nbsp;called&nbsp;Int(u),&nbsp;which&nbsp;is&nbsp;the&nbsp;largest&nbsp;value&nbsp;of&nbsp;the&nbsp;inter-pixel&nbsp;color<br>
&nbsp;&nbsp;&nbsp;&nbsp;difference&nbsp;between&nbsp;the&nbsp;adjacent&nbsp;pixels.&nbsp;&nbsp;In&nbsp;order&nbsp;to&nbsp;account&nbsp;for&nbsp;the&nbsp;fact<br>
&nbsp;&nbsp;&nbsp;&nbsp;that,&nbsp;at&nbsp;the&nbsp;beginning,&nbsp;each&nbsp;vertex&nbsp;consists&nbsp;of&nbsp;only&nbsp;one&nbsp;pixel&nbsp;[which&nbsp;would<br>
&nbsp;&nbsp;&nbsp;&nbsp;not&nbsp;allow&nbsp;for&nbsp;the&nbsp;calculation&nbsp;of&nbsp;Int(u)],&nbsp;the&nbsp;unary&nbsp;property&nbsp;of&nbsp;the&nbsp;pixels&nbsp;at<br>
&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;vertex&nbsp;is&nbsp;extended&nbsp;from&nbsp;Int(u)&nbsp;to&nbsp;MInt(u)&nbsp;with&nbsp;the&nbsp;addition&nbsp;of&nbsp;a&nbsp;vertex-size<br>
&nbsp;&nbsp;&nbsp;&nbsp;dependent&nbsp;number&nbsp;equal&nbsp;to&nbsp;k/|C|&nbsp;where&nbsp;"k"&nbsp;is&nbsp;a&nbsp;user-specified&nbsp;parameter&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;|C|&nbsp;the&nbsp;cardinality&nbsp;of&nbsp;the&nbsp;set&nbsp;of&nbsp;pixels&nbsp;represented&nbsp;by&nbsp;the&nbsp;vertex&nbsp;u&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;graph.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;As&nbsp;mentioned&nbsp;above,&nbsp;initially&nbsp;the&nbsp;edges&nbsp;in&nbsp;the&nbsp;graph&nbsp;representation&nbsp;of&nbsp;an<br>
&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;are&nbsp;set&nbsp;to&nbsp;the&nbsp;color&nbsp;difference&nbsp;between&nbsp;the&nbsp;two&nbsp;8-adjacent&nbsp;pixels&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;correspond&nbsp;to&nbsp;two&nbsp;different&nbsp;vertices.&nbsp;&nbsp;Subsequently,&nbsp;as&nbsp;the&nbsp;vertices&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;merged,&nbsp;an&nbsp;edge,&nbsp;E(u,v),&nbsp;between&nbsp;two&nbsp;vertices&nbsp;u&nbsp;and&nbsp;v&nbsp;is&nbsp;set&nbsp;to&nbsp;the&nbsp;smallest<br>
&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;of&nbsp;the&nbsp;inter-pixel&nbsp;color&nbsp;difference&nbsp;for&nbsp;two&nbsp;adjacent&nbsp;pixels&nbsp;that&nbsp;belong<br>
&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;two&nbsp;vertices.&nbsp;At&nbsp;each&nbsp;iteration&nbsp;of&nbsp;the&nbsp;algorithm,&nbsp;two&nbsp;vertices&nbsp;u&nbsp;and&nbsp;v<br>
&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;merged&nbsp;provided&nbsp;E(u,v)&nbsp;is&nbsp;less&nbsp;than&nbsp;the&nbsp;smaller&nbsp;of&nbsp;the&nbsp;MInt(u)&nbsp;or&nbsp;MInt(v)<br>
&nbsp;&nbsp;&nbsp;&nbsp;attributes&nbsp;at&nbsp;the&nbsp;two&nbsp;vertices.&nbsp;&nbsp;My&nbsp;experience&nbsp;is&nbsp;that&nbsp;for&nbsp;most&nbsp;images&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;algorithm&nbsp;terminates&nbsp;of&nbsp;its&nbsp;own&nbsp;accord&nbsp;after&nbsp;a&nbsp;small&nbsp;number&nbsp;of&nbsp;iterations<br>
&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;the&nbsp;vertex&nbsp;merging&nbsp;condition&nbsp;can&nbsp;be&nbsp;satisfied.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Since&nbsp;the&nbsp;algorithm&nbsp;is&nbsp;driven&nbsp;by&nbsp;the&nbsp;color&nbsp;differences&nbsp;between&nbsp;8-adjacent<br>
&nbsp;&nbsp;&nbsp;&nbsp;pixels,&nbsp;the&nbsp;FH&nbsp;algorithm&nbsp;is&nbsp;likely&nbsp;to&nbsp;create&nbsp;too&nbsp;fine&nbsp;a&nbsp;segmentation&nbsp;of&nbsp;an<br>
&nbsp;&nbsp;&nbsp;&nbsp;image.&nbsp;&nbsp;The&nbsp;segments&nbsp;produced&nbsp;by&nbsp;FH&nbsp;can&nbsp;be&nbsp;made&nbsp;larger&nbsp;by&nbsp;using&nbsp;the&nbsp;logic&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;SS&nbsp;that&nbsp;allows&nbsp;blobs&nbsp;of&nbsp;pixels&nbsp;to&nbsp;merge&nbsp;into&nbsp;larger&nbsp;blobs&nbsp;provided&nbsp;doing&nbsp;so<br>
&nbsp;&nbsp;&nbsp;&nbsp;makes&nbsp;sense&nbsp;based&nbsp;on&nbsp;the&nbsp;inter-blob&nbsp;values&nbsp;for&nbsp;mean&nbsp;color&nbsp;levels,&nbsp;color<br>
&nbsp;&nbsp;&nbsp;&nbsp;variances,&nbsp;texture&nbsp;values,&nbsp;etc.<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">INSTALLATION:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;YOLOLogic&nbsp;class&nbsp;was&nbsp;packaged&nbsp;using&nbsp;setuptools.&nbsp;&nbsp;For<br>
&nbsp;&nbsp;&nbsp;&nbsp;installation,&nbsp;execute&nbsp;the&nbsp;following&nbsp;command&nbsp;in&nbsp;the&nbsp;source&nbsp;directory&nbsp;(this&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;directory&nbsp;that&nbsp;contains&nbsp;the&nbsp;setup.py&nbsp;file&nbsp;after&nbsp;you&nbsp;have&nbsp;downloaded&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;uncompressed&nbsp;the&nbsp;package):<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sudo&nbsp;python3&nbsp;setup.py&nbsp;install<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;On&nbsp;Linux&nbsp;distributions,&nbsp;this&nbsp;will&nbsp;install&nbsp;the&nbsp;module&nbsp;file&nbsp;at&nbsp;a&nbsp;location&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;looks&nbsp;like<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/usr/local/lib/python3.8/dist-packages/<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;do&nbsp;not&nbsp;have&nbsp;root&nbsp;access,&nbsp;you&nbsp;have&nbsp;the&nbsp;option&nbsp;of&nbsp;working&nbsp;directly&nbsp;off<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;directory&nbsp;in&nbsp;which&nbsp;you&nbsp;downloaded&nbsp;the&nbsp;software&nbsp;by&nbsp;simply&nbsp;placing&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;following&nbsp;statements&nbsp;at&nbsp;the&nbsp;top&nbsp;of&nbsp;your&nbsp;scripts&nbsp;that&nbsp;use&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;class:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;sys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sys.path.append(&nbsp;"pathname_to_YOLOLogic_directory"&nbsp;)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;To&nbsp;uninstall&nbsp;the&nbsp;module,&nbsp;simply&nbsp;delete&nbsp;the&nbsp;source&nbsp;directory,&nbsp;locate&nbsp;where&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;module&nbsp;was&nbsp;installed&nbsp;with&nbsp;"locate<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic"&nbsp;and&nbsp;delete&nbsp;those&nbsp;files.&nbsp;&nbsp;As&nbsp;mentioned&nbsp;above,&nbsp;the&nbsp;full<br>
&nbsp;&nbsp;&nbsp;&nbsp;pathname&nbsp;to&nbsp;the&nbsp;installed&nbsp;version&nbsp;is&nbsp;likely&nbsp;to&nbsp;look&nbsp;like<br>
&nbsp;&nbsp;&nbsp;&nbsp;/usr/local/lib/python2.7/dist-packages/YOLOLogic*<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;carry&nbsp;out&nbsp;a&nbsp;non-standard&nbsp;install&nbsp;of&nbsp;the&nbsp;YOLOLogic<br>
&nbsp;&nbsp;&nbsp;&nbsp;module,&nbsp;look&nbsp;up&nbsp;the&nbsp;on-line&nbsp;information&nbsp;on&nbsp;Disutils&nbsp;by&nbsp;pointing&nbsp;your&nbsp;browser<br>
&nbsp;&nbsp;&nbsp;&nbsp;to<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://docs.python.org/dist/dist.html">http://docs.python.org/dist/dist.html</a><br>
&nbsp;<br>
<font size="+2" color="red">USAGE:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Single-Instance&nbsp;and&nbsp;Multi-Instance&nbsp;Detection:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;wish&nbsp;to&nbsp;experiment&nbsp;with&nbsp;the&nbsp;YOLO&nbsp;logic&nbsp;for&nbsp;multi-instance&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;detection,&nbsp;you&nbsp;would&nbsp;need&nbsp;to&nbsp;construct&nbsp;an&nbsp;instance&nbsp;of&nbsp;the&nbsp;YOLOLogic&nbsp;class&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;invoke&nbsp;the&nbsp;methods&nbsp;shown&nbsp;below&nbsp;on&nbsp;this&nbsp;instance:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;yolo&nbsp;=&nbsp;YOLOLogic(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;##&nbsp;The&nbsp;following&nbsp;two&nbsp;statements&nbsp;are&nbsp;for&nbsp;the&nbsp;single-instance&nbsp;script:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataroot_train&nbsp;=&nbsp;"./data/Purdue_Dr_Eval_dataset_train_10000/",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataroot_test&nbsp;=&nbsp;"./data/Purdue_Dr_Eval_dataset_test_1000/",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;##&nbsp;The&nbsp;following&nbsp;two&nbsp;statements&nbsp;are&nbsp;for&nbsp;the&nbsp;multi-instance&nbsp;script:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;dataroot_train&nbsp;=&nbsp;"./data/Purdue_Dr_Eval_multi_dataset_train_10000/"&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;dataroot_test&nbsp;&nbsp;=&nbsp;"./data/Purdue_Dr_Eval_multi_dataset_test_1000/",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_size&nbsp;=&nbsp;[128,128],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yolo_interval&nbsp;=&nbsp;20,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;path_saved_yolo_model&nbsp;=&nbsp;"./saved_yolo_model",<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;momentum&nbsp;=&nbsp;0.9,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;learning_rate&nbsp;=&nbsp;1e-6,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;epochs&nbsp;=&nbsp;40,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch_size&nbsp;=&nbsp;4,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;classes&nbsp;=&nbsp;('Dr_Eval','house','watertower'),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;use_gpu&nbsp;=&nbsp;True,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;yolo&nbsp;=&nbsp;YOLOLogic.YoloObjectDetector(&nbsp;yolo&nbsp;=&nbsp;yolo&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;yolo.set_dataloaders(train=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;yolo.set_dataloaders(test=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;model&nbsp;=&nbsp;yolo.NetForYolo(skip_connections=True,&nbsp;depth=8)&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;model&nbsp;=&nbsp;yolo.run_code_for_training_multi_instance_detection(model,&nbsp;display_images=False)<br>
&nbsp;&nbsp;&nbsp;&nbsp;yolo.run_code_for_training_multi_instance_detection(model,&nbsp;display_images&nbsp;=&nbsp;True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Graph-Based&nbsp;Algorithms&nbsp;for&nbsp;Region&nbsp;Proposals:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;To&nbsp;generate&nbsp;region&nbsp;proposals,&nbsp;you&nbsp;would&nbsp;need&nbsp;to&nbsp;construct&nbsp;an&nbsp;instance&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;class&nbsp;and&nbsp;invoke&nbsp;the&nbsp;methods&nbsp;shown&nbsp;below&nbsp;on&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;instance:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yolo&nbsp;=&nbsp;YOLOLogic(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;###&nbsp;&nbsp;The&nbsp;first&nbsp;6&nbsp;options&nbsp;affect&nbsp;only&nbsp;the&nbsp;Graph-Based&nbsp;part&nbsp;of&nbsp;the&nbsp;algo<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sigma&nbsp;=&nbsp;1.0,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_iterations&nbsp;=&nbsp;40,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kay&nbsp;=&nbsp;0.05,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_normalization_required&nbsp;=&nbsp;True,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_size_reduction_factor&nbsp;=&nbsp;4,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;min_size_for_graph_based_blobs&nbsp;=&nbsp;4,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;###&nbsp;&nbsp;The&nbsp;next&nbsp;4&nbsp;options&nbsp;affect&nbsp;only&nbsp;the&nbsp;Selective&nbsp;Search&nbsp;part&nbsp;of&nbsp;the&nbsp;algo<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;color_homogeneity_thresh&nbsp;=&nbsp;[20,20,20],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;gray_var_thresh&nbsp;=&nbsp;16000,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;texture_homogeneity_thresh&nbsp;=&nbsp;120,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_num_blobs_expected&nbsp;=&nbsp;8,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_name&nbsp;=&nbsp;"images/mondrian.jpg"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;segmented_graph,color_map&nbsp;=&nbsp;yolo.graph_based_segmentation(image_name)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yolo.visualize_segmentation_in_pseudocolor(segmented_graph[0],&nbsp;color_map,&nbsp;"graph_based"&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;merged_blobs,&nbsp;color_map&nbsp;=&nbsp;yolo.selective_search_for_region_proposals(&nbsp;segmented_graph,&nbsp;image_name&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;yolo.visualize_segmentation_with_mean_gray(merged_blobs,&nbsp;"ss_based_segmentation_in_bw"&nbsp;)<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">CONSTRUCTOR&nbsp;PARAMETERS:&nbsp;<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Of&nbsp;the&nbsp;10&nbsp;constructor&nbsp;parameters&nbsp;listed&nbsp;below,&nbsp;the&nbsp;first&nbsp;six&nbsp;are&nbsp;meant&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;FH&nbsp;algorithm&nbsp;and&nbsp;the&nbsp;last&nbsp;four&nbsp;for&nbsp;the&nbsp;SS&nbsp;algorithm.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;sigma:&nbsp;Controls&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;Gaussian&nbsp;kernel&nbsp;used&nbsp;for&nbsp;smoothing&nbsp;the&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;before&nbsp;its&nbsp;gradient&nbsp;is&nbsp;calculated.&nbsp;&nbsp;Assuming&nbsp;the&nbsp;pixel<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sampling&nbsp;interval&nbsp;to&nbsp;be&nbsp;unity,&nbsp;a&nbsp;sigma&nbsp;of&nbsp;1&nbsp;gives&nbsp;you&nbsp;a&nbsp;7x7<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;smoothing&nbsp;operator&nbsp;with&nbsp;Gaussian&nbsp;weighting.&nbsp;&nbsp;The&nbsp;default&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;parameter&nbsp;is&nbsp;1.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_iterations:&nbsp;Sets&nbsp;an&nbsp;upper&nbsp;limit&nbsp;on&nbsp;the&nbsp;number&nbsp;of&nbsp;iterations&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;graph-based&nbsp;FH&nbsp;algorithm&nbsp;for&nbsp;image&nbsp;segmentation.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;kay:&nbsp;This&nbsp;is&nbsp;the&nbsp;same&nbsp;as&nbsp;the&nbsp;"k"&nbsp;parameter&nbsp;in&nbsp;the&nbsp;FH&nbsp;algorithm.&nbsp;&nbsp;As&nbsp;mentioned<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;Introduction&nbsp;above,&nbsp;the&nbsp;Int(u)&nbsp;property&nbsp;of&nbsp;the&nbsp;pixels<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;represented&nbsp;by&nbsp;each&nbsp;vertex&nbsp;in&nbsp;the&nbsp;graph&nbsp;representation&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;is&nbsp;extended&nbsp;to&nbsp;MInt(u)&nbsp;by&nbsp;the&nbsp;addition&nbsp;of&nbsp;a&nbsp;number&nbsp;k/|C|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where&nbsp;|C|&nbsp;is&nbsp;the&nbsp;cardinality&nbsp;of&nbsp;the&nbsp;set&nbsp;of&nbsp;pixels&nbsp;at&nbsp;that<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vertex.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;image_normalization_required:&nbsp;This&nbsp;applies&nbsp;Torchvision's&nbsp;image&nbsp;normalization<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;pixel&nbsp;values&nbsp;in&nbsp;the&nbsp;image.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;image_size_reduction_factor:&nbsp;As&nbsp;mentioned&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;this&nbsp;document,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;is&nbsp;really&nbsp;not&nbsp;meant&nbsp;for&nbsp;production<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;work.&nbsp;&nbsp;The&nbsp;code&nbsp;is&nbsp;pure&nbsp;Python&nbsp;and,&nbsp;even&nbsp;with&nbsp;that,&nbsp;not&nbsp;at&nbsp;all<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimized.&nbsp;&nbsp;The&nbsp;focus&nbsp;of&nbsp;the&nbsp;module&nbsp;is&nbsp;primarily&nbsp;on&nbsp;easy<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;understandability&nbsp;of&nbsp;what&nbsp;the&nbsp;code&nbsp;is&nbsp;doing&nbsp;so&nbsp;that&nbsp;you&nbsp;can<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;experiment&nbsp;with&nbsp;the&nbsp;algorithm&nbsp;itself.&nbsp;&nbsp;For&nbsp;the&nbsp;module&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;produce&nbsp;results&nbsp;within&nbsp;a&nbsp;reasonable&nbsp;length&nbsp;of&nbsp;time,&nbsp;you&nbsp;can<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;use&nbsp;this&nbsp;constructor&nbsp;parameter&nbsp;to&nbsp;downsize&nbsp;the&nbsp;array&nbsp;of&nbsp;pixels<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;the&nbsp;module&nbsp;must&nbsp;work&nbsp;with.&nbsp;&nbsp;Set&nbsp;this&nbsp;parameter&nbsp;to&nbsp;a&nbsp;value<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;so&nbsp;that&nbsp;the&nbsp;initial&nbsp;graph&nbsp;constructed&nbsp;from&nbsp;the&nbsp;image&nbsp;has&nbsp;no<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;more&nbsp;than&nbsp;around&nbsp;3500&nbsp;vertices&nbsp;if&nbsp;you&nbsp;don't&nbsp;want&nbsp;to&nbsp;wait&nbsp;too<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;long&nbsp;for&nbsp;the&nbsp;results.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;min_size_for_graph_based_blobs:&nbsp;This&nbsp;declares&nbsp;a&nbsp;threshold&nbsp;on&nbsp;the&nbsp;smallest&nbsp;size<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;you'd&nbsp;like&nbsp;to&nbsp;see&nbsp;(in&nbsp;terms&nbsp;of&nbsp;the&nbsp;number&nbsp;of&nbsp;pixels)&nbsp;in&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;segmented&nbsp;blob&nbsp;in&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;graph-based&nbsp;segmenter.&nbsp;&nbsp;(I<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;typically&nbsp;use&nbsp;values&nbsp;from&nbsp;1&nbsp;to&nbsp;4&nbsp;for&nbsp;this&nbsp;parameter.)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;color_homogeneity_thresh:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;and&nbsp;the&nbsp;next&nbsp;three&nbsp;constructor&nbsp;options&nbsp;are&nbsp;meant<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;specifically&nbsp;for&nbsp;the&nbsp;SS&nbsp;algorithm&nbsp;that&nbsp;sits&nbsp;on&nbsp;top&nbsp;of&nbsp;the&nbsp;FH<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithm&nbsp;for&nbsp;further&nbsp;merging&nbsp;of&nbsp;the&nbsp;pixel&nbsp;blobs&nbsp;produced&nbsp;by<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FH.&nbsp;&nbsp;This&nbsp;constructor&nbsp;option&nbsp;specifies&nbsp;the&nbsp;maximum&nbsp;allowable<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;difference&nbsp;between&nbsp;the&nbsp;mean&nbsp;color&nbsp;values&nbsp;in&nbsp;two&nbsp;pixel&nbsp;blobs<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;them&nbsp;to&nbsp;be&nbsp;merged.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;gray_var_thresh:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;option&nbsp;declares&nbsp;the&nbsp;maximum&nbsp;allowable&nbsp;difference&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;variances&nbsp;in&nbsp;the&nbsp;grayscale&nbsp;in&nbsp;two&nbsp;blobs&nbsp;if&nbsp;they&nbsp;are&nbsp;to&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;merged.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;texture_homogeneity_thresh:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;YOLOLogic&nbsp;module&nbsp;characterizes&nbsp;the&nbsp;texture&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;pixels&nbsp;in&nbsp;each&nbsp;segmented&nbsp;blob&nbsp;by&nbsp;its&nbsp;LBP&nbsp;(Local&nbsp;Binary<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Patterns)&nbsp;texture.&nbsp;&nbsp;We&nbsp;want&nbsp;the&nbsp;LBP&nbsp;texture&nbsp;values&nbsp;for&nbsp;two<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;blobs&nbsp;to&nbsp;be&nbsp;within&nbsp;the&nbsp;value&nbsp;specified&nbsp;by&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;option&nbsp;if&nbsp;those&nbsp;blobs&nbsp;are&nbsp;to&nbsp;be&nbsp;merged.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;max_num_blobs_expected:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;you&nbsp;only&nbsp;want&nbsp;to&nbsp;extract&nbsp;a&nbsp;certain&nbsp;number&nbsp;of&nbsp;the&nbsp;largest<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;possible&nbsp;blobs,&nbsp;you&nbsp;can&nbsp;do&nbsp;that&nbsp;by&nbsp;giving&nbsp;a&nbsp;value&nbsp;to&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;constructor&nbsp;option.<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">Inner&nbsp;Classes:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(1)&nbsp;&nbsp;PurdueDrEvalDataset<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;the&nbsp;dataset&nbsp;to&nbsp;use&nbsp;if&nbsp;you&nbsp;are&nbsp;experimenting&nbsp;with&nbsp;single-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection.&nbsp;&nbsp;The&nbsp;dataset&nbsp;contains&nbsp;three&nbsp;kinds&nbsp;of&nbsp;objects&nbsp;in&nbsp;its<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;images:&nbsp;Dr.&nbsp;Eval,&nbsp;and&nbsp;two&nbsp;"objects"&nbsp;in&nbsp;his&nbsp;neighborhood:&nbsp;a&nbsp;house&nbsp;and&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;watertower.&nbsp;&nbsp;Each&nbsp;128x128&nbsp;image&nbsp;in&nbsp;the&nbsp;dataset&nbsp;contains&nbsp;one&nbsp;of&nbsp;these<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objects&nbsp;after&nbsp;it&nbsp;is&nbsp;randomly&nbsp;scaled&nbsp;and&nbsp;colored.&nbsp;Each&nbsp;image&nbsp;also&nbsp;contains<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;substantial&nbsp;structured&nbsp;noise&nbsp;in&nbsp;addition&nbsp;to&nbsp;20%&nbsp;Gaussian&nbsp;noise.&nbsp;&nbsp;Examples<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;these&nbsp;images&nbsp;are&nbsp;shown&nbsp;in&nbsp;the&nbsp;Week&nbsp;7&nbsp;lecture&nbsp;material&nbsp;in&nbsp;Purdue's&nbsp;Deep<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Learning&nbsp;class.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(2)&nbsp;&nbsp;PurdueDrEvalMultiDataset<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;the&nbsp;dataset&nbsp;to&nbsp;use&nbsp;if&nbsp;you&nbsp;are&nbsp;experimenting&nbsp;with&nbsp;multi-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object&nbsp;detection.&nbsp;&nbsp;Each&nbsp;image&nbsp;in&nbsp;the&nbsp;dataset&nbsp;contains&nbsp;randomly&nbsp;chosen<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;multiple&nbsp;instances&nbsp;of&nbsp;the&nbsp;same&nbsp;three&nbsp;kinds&nbsp;of&nbsp;objects&nbsp;as&nbsp;mentioned&nbsp;above:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dr.&nbsp;Eval,&nbsp;house,&nbsp;and&nbsp;watertower.&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;object&nbsp;instances&nbsp;in&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;is&nbsp;limited&nbsp;to&nbsp;a&nbsp;maximum&nbsp;of&nbsp;five.&nbsp;&nbsp;The&nbsp;images&nbsp;contain&nbsp;substantial<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;amount&nbsp;of&nbsp;structured&nbsp;noise&nbsp;in&nbsp;addition&nbsp;to&nbsp;20%&nbsp;random&nbsp;noise.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;reason&nbsp;for&nbsp;why&nbsp;the&nbsp;above&nbsp;two&nbsp;datasets&nbsp;have&nbsp;"DrEval"&nbsp;in&nbsp;their&nbsp;names:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;having&nbsp;watched&nbsp;every&nbsp;contemporary&nbsp;movie&nbsp;at&nbsp;Netflix&nbsp;that&nbsp;was&nbsp;worth<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;watching,&nbsp;my&nbsp;wife&nbsp;and&nbsp;I&nbsp;decided&nbsp;to&nbsp;revisit&nbsp;some&nbsp;of&nbsp;old&nbsp;movies&nbsp;that&nbsp;we&nbsp;had<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enjoyed&nbsp;a&nbsp;long&nbsp;time&nbsp;back.&nbsp;&nbsp;That&nbsp;led&nbsp;us&nbsp;to&nbsp;watching&nbsp;again&nbsp;a&nbsp;couple&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Austin&nbsp;Powers&nbsp;movies.&nbsp;&nbsp;If&nbsp;you&nbsp;are&nbsp;too&nbsp;young&nbsp;to&nbsp;know&nbsp;what&nbsp;I&nbsp;am&nbsp;talking<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;about,&nbsp;these&nbsp;movies&nbsp;are&nbsp;spoofs&nbsp;on&nbsp;the&nbsp;James&nbsp;Bond&nbsp;movies&nbsp;in&nbsp;which&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;great&nbsp;comedian&nbsp;Mike&nbsp;Myers&nbsp;plays&nbsp;both&nbsp;Austin&nbsp;Powers&nbsp;and&nbsp;his&nbsp;nemesis<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dr.&nbsp;Evil.&nbsp;&nbsp;Around&nbsp;the&nbsp;same&nbsp;time,&nbsp;I&nbsp;was&nbsp;writing&nbsp;code&nbsp;for&nbsp;the&nbsp;two&nbsp;datasets<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mentioned&nbsp;above.&nbsp;&nbsp;One&nbsp;of&nbsp;the&nbsp;three&nbsp;objects&nbsp;types&nbsp;in&nbsp;these&nbsp;images&nbsp;is&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;human-like&nbsp;cartoon&nbsp;figure&nbsp;that&nbsp;I&nbsp;needed&nbsp;a&nbsp;name&nbsp;for.&nbsp;&nbsp;So,&nbsp;after&nbsp;Dr.&nbsp;Evil<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;movies,&nbsp;I&nbsp;decided&nbsp;to&nbsp;call&nbsp;this&nbsp;cartoon&nbsp;figure&nbsp;Dr&nbsp;Eval&nbsp;and&nbsp;to&nbsp;refer<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to&nbsp;the&nbsp;datasets&nbsp;as&nbsp;Dr&nbsp;Eval&nbsp;datasets.&nbsp;As&nbsp;you&nbsp;all&nbsp;know,&nbsp;"Eval"&nbsp;is&nbsp;an<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;important&nbsp;word&nbsp;for&nbsp;people&nbsp;like&nbsp;us.&nbsp;&nbsp;All&nbsp;programming&nbsp;languages&nbsp;provide&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function&nbsp;with&nbsp;a&nbsp;name&nbsp;like&nbsp;"eval()".<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(3)&nbsp;&nbsp;SingleInstanceDetector<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;provides&nbsp;a&nbsp;reference&nbsp;implementation&nbsp;for&nbsp;constructing&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;single-instance&nbsp;object&nbsp;detector&nbsp;to&nbsp;be&nbsp;used&nbsp;for&nbsp;the&nbsp;PurdueDrEvalDataset<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataset.&nbsp;For&nbsp;the&nbsp;detection&nbsp;and&nbsp;regression&nbsp;network,&nbsp;it&nbsp;uses&nbsp;the&nbsp;LOADnet2<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;network&nbsp;from&nbsp;DLStudio&nbsp;with&nbsp;small&nbsp;modifications&nbsp;to&nbsp;account&nbsp;for&nbsp;the&nbsp;larger<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;128x128&nbsp;images&nbsp;in&nbsp;the&nbsp;dataset.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(4)&nbsp;&nbsp;YoloObjectDetector&nbsp;&nbsp;&nbsp;[For&nbsp;multi-instance&nbsp;detection]<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;code&nbsp;in&nbsp;this&nbsp;inner&nbsp;class&nbsp;provides&nbsp;an&nbsp;implementation&nbsp;for&nbsp;the&nbsp;key<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elements&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;logic&nbsp;for&nbsp;multi-instance&nbsp;object&nbsp;detection.&nbsp;&nbsp;Each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training&nbsp;image&nbsp;is&nbsp;divided&nbsp;into&nbsp;a&nbsp;grid&nbsp;of&nbsp;cells&nbsp;and&nbsp;it&nbsp;is&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;responsibility&nbsp;of&nbsp;the&nbsp;cell&nbsp;that&nbsp;contains&nbsp;the&nbsp;center&nbsp;of&nbsp;an&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bounding-box&nbsp;to&nbsp;provide&nbsp;at&nbsp;the&nbsp;output&nbsp;of&nbsp;the&nbsp;neural&nbsp;network&nbsp;an&nbsp;estimate<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;the&nbsp;exact&nbsp;location&nbsp;of&nbsp;the&nbsp;center&nbsp;of&nbsp;the&nbsp;object&nbsp;bounding&nbsp;box&nbsp;vis-a-vis<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;center&nbsp;of&nbsp;the&nbsp;cell.&nbsp;&nbsp;That&nbsp;cell&nbsp;must&nbsp;also&nbsp;lead&nbsp;to&nbsp;an&nbsp;estimate&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;height&nbsp;and&nbsp;the&nbsp;width&nbsp;of&nbsp;the&nbsp;bounding-box&nbsp;for&nbsp;the&nbsp;object&nbsp;instance.<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">PUBLIC&nbsp;METHODS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Many&nbsp;of&nbsp;these&nbsp;method&nbsp;are&nbsp;related&nbsp;to&nbsp;using&nbsp;this&nbsp;module&nbsp;for&nbsp;experimenting&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;traditional&nbsp;graph-based&nbsp;algorithms&nbsp;for&nbsp;constructing&nbsp;region&nbsp;proposals&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;images:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(1)&nbsp;&nbsp;selective_search_for_region_proposals()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;implements&nbsp;elements&nbsp;of&nbsp;the&nbsp;Selective&nbsp;Search&nbsp;(SS)&nbsp;algorithm<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposed&nbsp;by&nbsp;Uijlings,&nbsp;van&nbsp;de&nbsp;Sande,&nbsp;Gevers,&nbsp;and&nbsp;Smeulders&nbsp;for&nbsp;creating<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;region&nbsp;proposals&nbsp;for&nbsp;object&nbsp;detection.&nbsp;&nbsp;As&nbsp;mentioned&nbsp;elsewhere&nbsp;here,&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithm&nbsp;sits&nbsp;on&nbsp;top&nbsp;of&nbsp;the&nbsp;graph&nbsp;based&nbsp;image&nbsp;segmentation&nbsp;algorithm<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;was&nbsp;proposed&nbsp;by&nbsp;Felzenszwalb&nbsp;and&nbsp;Huttenlocher.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(2)&nbsp;&nbsp;graph_based_segmentation()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;an&nbsp;implementation&nbsp;of&nbsp;the&nbsp;Felzenszwalb&nbsp;and&nbsp;Huttenlocher&nbsp;(FH)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithm&nbsp;for&nbsp;graph-based&nbsp;segmentation&nbsp;of&nbsp;images.&nbsp;&nbsp;At&nbsp;the&nbsp;moment,&nbsp;it&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;limited&nbsp;to&nbsp;working&nbsp;on&nbsp;grayscale&nbsp;images.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(3)&nbsp;&nbsp;display_tensor_as_image()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;converts&nbsp;the&nbsp;argument&nbsp;tensor&nbsp;into&nbsp;a&nbsp;photo&nbsp;image&nbsp;that&nbsp;you&nbsp;can<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;display&nbsp;in&nbsp;your&nbsp;terminal&nbsp;screen.&nbsp;It&nbsp;can&nbsp;convert&nbsp;tensors&nbsp;of&nbsp;three<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;different&nbsp;shapes&nbsp;into&nbsp;images:&nbsp;(3,H,W),&nbsp;(1,H,W),&nbsp;and&nbsp;(H,W),&nbsp;where&nbsp;H,&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;height,&nbsp;stands&nbsp;for&nbsp;the&nbsp;number&nbsp;of&nbsp;pixel&nbsp;in&nbsp;the&nbsp;vertical&nbsp;direction&nbsp;and&nbsp;W,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;width,&nbsp;the&nbsp;same&nbsp;along&nbsp;the&nbsp;horizontal&nbsp;direction.&nbsp;When&nbsp;the&nbsp;first<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;element&nbsp;of&nbsp;the&nbsp;shape&nbsp;is&nbsp;3,&nbsp;that&nbsp;means&nbsp;that&nbsp;the&nbsp;tensor&nbsp;represents&nbsp;a&nbsp;color<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;in&nbsp;which&nbsp;each&nbsp;pixel&nbsp;in&nbsp;the&nbsp;(H,W)&nbsp;plane&nbsp;has&nbsp;three&nbsp;values&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;three&nbsp;color&nbsp;channels.&nbsp;&nbsp;On&nbsp;the&nbsp;other&nbsp;hand,&nbsp;when&nbsp;the&nbsp;first&nbsp;element&nbsp;is&nbsp;1,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;stands&nbsp;for&nbsp;a&nbsp;tensor&nbsp;that&nbsp;will&nbsp;be&nbsp;shown&nbsp;as&nbsp;a&nbsp;grayscale&nbsp;image.&nbsp;&nbsp;And<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;when&nbsp;the&nbsp;shape&nbsp;is&nbsp;just&nbsp;(H,W),&nbsp;that&nbsp;is&nbsp;automatically&nbsp;taken&nbsp;to&nbsp;be&nbsp;for&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grayscale&nbsp;image.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(4)&nbsp;&nbsp;graying_resizing_binarizing()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;demonstration&nbsp;of&nbsp;some&nbsp;of&nbsp;the&nbsp;more&nbsp;basic&nbsp;and&nbsp;commonly&nbsp;used&nbsp;image<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transformations&nbsp;from&nbsp;the&nbsp;torchvision.transformations&nbsp;module.&nbsp;&nbsp;The&nbsp;large<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;comment&nbsp;blocks&nbsp;are&nbsp;meant&nbsp;to&nbsp;serve&nbsp;as&nbsp;tutorial&nbsp;introduction&nbsp;to&nbsp;the&nbsp;syntax<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;used&nbsp;for&nbsp;invoking&nbsp;these&nbsp;transformations.&nbsp;&nbsp;The&nbsp;transformations&nbsp;shown&nbsp;can<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;be&nbsp;used&nbsp;for&nbsp;converting&nbsp;a&nbsp;color&nbsp;image&nbsp;into&nbsp;a&nbsp;grayscale&nbsp;image,&nbsp;for&nbsp;resizing<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;image,&nbsp;for&nbsp;converting&nbsp;a&nbsp;PIL.Image&nbsp;into&nbsp;a&nbsp;tensor&nbsp;and&nbsp;a&nbsp;tensor&nbsp;back&nbsp;into<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;PIL.Image&nbsp;object,&nbsp;and&nbsp;so&nbsp;on.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(5)&nbsp;&nbsp;accessing_one_color_plane()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;shows&nbsp;how&nbsp;can&nbsp;access&nbsp;the&nbsp;n-th&nbsp;color&nbsp;plane&nbsp;of&nbsp;the&nbsp;argument<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;color&nbsp;image.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(6)&nbsp;&nbsp;working_with_hsv_color_space()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Illustrates&nbsp;converting&nbsp;an&nbsp;RGB&nbsp;color&nbsp;image&nbsp;into&nbsp;its&nbsp;HSV&nbsp;representation.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(7)&nbsp;&nbsp;histogramming_the_image()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PyTorch&nbsp;based&nbsp;experiments&nbsp;with&nbsp;histogramming&nbsp;the&nbsp;grayscale&nbsp;and&nbsp;the&nbsp;color<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;values&nbsp;in&nbsp;an&nbsp;image<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(8)&nbsp;&nbsp;histogramming_and_thresholding():<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;illustrates&nbsp;using&nbsp;the&nbsp;PyTorch&nbsp;functionality&nbsp;for&nbsp;histogramming<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;thresholding&nbsp;individual&nbsp;images.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(9)&nbsp;&nbsp;convolutions_with_pytorch()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;calls&nbsp;on&nbsp;torch.nn.functional.conv2d()&nbsp;for&nbsp;demonstrating&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;single&nbsp;image&nbsp;convolution&nbsp;with&nbsp;a&nbsp;specified&nbsp;kernel.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(10)&nbsp;gaussian_smooth()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;smooths&nbsp;an&nbsp;image&nbsp;with&nbsp;a&nbsp;Gaussian&nbsp;of&nbsp;specified&nbsp;sigma.&nbsp;&nbsp;You&nbsp;can<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;do&nbsp;the&nbsp;same&nbsp;much&nbsp;faster&nbsp;by&nbsp;using&nbsp;the&nbsp;functionality&nbsp;programmed&nbsp;into<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torch.nn.functional.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(11)&nbsp;visualize_segmentation_in_pseudocolor()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After&nbsp;an&nbsp;image&nbsp;has&nbsp;been&nbsp;segmented,&nbsp;this&nbsp;method&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;assign&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random&nbsp;color&nbsp;to&nbsp;each&nbsp;blob&nbsp;in&nbsp;the&nbsp;segmented&nbsp;output&nbsp;for&nbsp;a&nbsp;better<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;visualization&nbsp;of&nbsp;the&nbsp;segmentation.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(12)&nbsp;visualize_segmentation_with_mean_gray()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If&nbsp;the&nbsp;visualization&nbsp;produced&nbsp;by&nbsp;the&nbsp;previous&nbsp;method&nbsp;appears&nbsp;too&nbsp;chaotic,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;you&nbsp;can&nbsp;use&nbsp;this&nbsp;method&nbsp;to&nbsp;assign&nbsp;the&nbsp;mean&nbsp;color&nbsp;to&nbsp;each&nbsp;each&nbsp;blob&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output&nbsp;of&nbsp;an&nbsp;image&nbsp;segmentation&nbsp;algorithm.&nbsp;&nbsp;The&nbsp;mean&nbsp;color&nbsp;is&nbsp;derived<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;the&nbsp;pixel&nbsp;values&nbsp;in&nbsp;the&nbsp;blob.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(13)&nbsp;extract_image_region_interactively_by_dragging_mouse()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You&nbsp;can&nbsp;use&nbsp;this&nbsp;method&nbsp;to&nbsp;apply&nbsp;the&nbsp;graph-based&nbsp;segmentation&nbsp;and&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;selective&nbsp;search&nbsp;algorithms&nbsp;to&nbsp;just&nbsp;a&nbsp;portion&nbsp;of&nbsp;your&nbsp;image.&nbsp;&nbsp;This&nbsp;method<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;extract&nbsp;the&nbsp;portion&nbsp;you&nbsp;want.&nbsp;&nbsp;You&nbsp;click&nbsp;at&nbsp;the&nbsp;upper&nbsp;left&nbsp;corner&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rectangular&nbsp;portion&nbsp;of&nbsp;the&nbsp;image&nbsp;you&nbsp;are&nbsp;interested&nbsp;in&nbsp;and&nbsp;you&nbsp;then&nbsp;drag<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;mouse&nbsp;pointer&nbsp;to&nbsp;the&nbsp;lower&nbsp;right&nbsp;corner.&nbsp;&nbsp;Make&nbsp;sure&nbsp;that&nbsp;you&nbsp;click&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"save"&nbsp;and&nbsp;"exit"&nbsp;after&nbsp;you&nbsp;have&nbsp;delineated&nbsp;the&nbsp;area.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(14)&nbsp;extract_image_region_interactively_through_mouse_clicks()<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;allows&nbsp;a&nbsp;user&nbsp;to&nbsp;use&nbsp;a&nbsp;sequence&nbsp;of&nbsp;mouse&nbsp;clicks&nbsp;in&nbsp;order&nbsp;to<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;specify&nbsp;a&nbsp;region&nbsp;of&nbsp;the&nbsp;input&nbsp;image&nbsp;that&nbsp;should&nbsp;be&nbsp;subject&nbsp;to&nbsp;further<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;processing.&nbsp;&nbsp;The&nbsp;mouse&nbsp;clicks&nbsp;taken&nbsp;together&nbsp;define&nbsp;a&nbsp;polygon.&nbsp;The&nbsp;method<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;encloses&nbsp;the&nbsp;polygonal&nbsp;region&nbsp;by&nbsp;a&nbsp;minimum&nbsp;bounding&nbsp;rectangle,&nbsp;which&nbsp;then<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;becomes&nbsp;the&nbsp;new&nbsp;input&nbsp;image&nbsp;for&nbsp;the&nbsp;rest&nbsp;of&nbsp;processing.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(15)&nbsp;displaying_and_histogramming_images_in_batch1(image_dir,&nbsp;batch_size)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;is&nbsp;the&nbsp;first&nbsp;of&nbsp;three&nbsp;such&nbsp;methods&nbsp;in&nbsp;this&nbsp;module&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;illustrating&nbsp;the&nbsp;functionality&nbsp;of&nbsp;matplotlib&nbsp;for&nbsp;simultaneously<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;displaying&nbsp;multiple&nbsp;images&nbsp;and&nbsp;the&nbsp;results&nbsp;obtained&nbsp;from&nbsp;them&nbsp;in&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;gridded&nbsp;arrangement.&nbsp;&nbsp;The&nbsp;core&nbsp;idea&nbsp;in&nbsp;this&nbsp;method&nbsp;is&nbsp;to&nbsp;call<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"plt.subplots(2,batch_size)"&nbsp;to&nbsp;create&nbsp;'batch_size'&nbsp;number&nbsp;of&nbsp;subplot<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objects,&nbsp;called&nbsp;"axes",&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;a&nbsp;'2xbatch_size'&nbsp;array.&nbsp;We&nbsp;use&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;row&nbsp;of&nbsp;this&nbsp;grid&nbsp;to&nbsp;display&nbsp;each&nbsp;image&nbsp;in&nbsp;its&nbsp;own&nbsp;subplot&nbsp;object.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And&nbsp;we&nbsp;use&nbsp;the&nbsp;second&nbsp;row&nbsp;of&nbsp;the&nbsp;grid&nbsp;to&nbsp;display&nbsp;the&nbsp;histograms&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;corresponding&nbsp;images&nbsp;in&nbsp;the&nbsp;first&nbsp;row.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(16)&nbsp;displaying_and_histogramming_images_in_batch2(image_dir,&nbsp;batch_size)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I&nbsp;now&nbsp;show&nbsp;a&nbsp;second&nbsp;approach&nbsp;to&nbsp;displaying&nbsp;multiple&nbsp;images&nbsp;and&nbsp;their<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;corresponding&nbsp;histograms&nbsp;in&nbsp;a&nbsp;gridded&nbsp;display.&nbsp;&nbsp;In&nbsp;this&nbsp;method&nbsp;we&nbsp;call&nbsp;on<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"torchvision.utils.make_grid()"&nbsp;to&nbsp;construct&nbsp;a&nbsp;grid&nbsp;for&nbsp;us.&nbsp;&nbsp;The&nbsp;grid&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;created&nbsp;by&nbsp;giving&nbsp;an&nbsp;argument&nbsp;like&nbsp;"nrow=4"&nbsp;to&nbsp;it.&nbsp;&nbsp;The&nbsp;grid&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;returned&nbsp;by&nbsp;the&nbsp;call&nbsp;to&nbsp;make_grid()&nbsp;is&nbsp;a&nbsp;tensor&nbsp;unto&nbsp;itself.&nbsp;Such&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;object&nbsp;is&nbsp;converted&nbsp;into&nbsp;a&nbsp;numpy&nbsp;array&nbsp;so&nbsp;that&nbsp;it&nbsp;can&nbsp;be&nbsp;displayed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;by&nbsp;matplotlib's&nbsp;"imshow()"&nbsp;function.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;(17)&nbsp;displaying_and_histogramming_images_in_batch3(image_dir,&nbsp;batch_size)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;illustrates&nbsp;two&nbsp;things:&nbsp;(1)&nbsp;The&nbsp;syntax&nbsp;used&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'singular'&nbsp;version&nbsp;of&nbsp;the&nbsp;subplot&nbsp;function&nbsp;"plt.subplot()"&nbsp;---&nbsp;although<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I'll&nbsp;be&nbsp;doing&nbsp;so&nbsp;by&nbsp;actually&nbsp;calling&nbsp;"fig.add_subplot()".&nbsp;&nbsp;And&nbsp;(2)&nbsp;How<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;you&nbsp;can&nbsp;put&nbsp;together&nbsp;multiple&nbsp;multi-image&nbsp;plots&nbsp;by&nbsp;creating&nbsp;multiple<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Figure&nbsp;objects.&nbsp;&nbsp;'Figure'&nbsp;is&nbsp;the&nbsp;top-level&nbsp;container&nbsp;of&nbsp;plots&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;matplotlib.&nbsp;&nbsp;This&nbsp;method&nbsp;creates&nbsp;two&nbsp;separate&nbsp;Figure&nbsp;objects,&nbsp;one&nbsp;as&nbsp;a<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;container&nbsp;for&nbsp;all&nbsp;the&nbsp;images&nbsp;in&nbsp;a&nbsp;batch&nbsp;and&nbsp;the&nbsp;other&nbsp;as&nbsp;a&nbsp;container&nbsp;for<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;all&nbsp;the&nbsp;histograms&nbsp;for&nbsp;the&nbsp;images.&nbsp;&nbsp;The&nbsp;two&nbsp;Figure&nbsp;containers&nbsp;are<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;displayed&nbsp;in&nbsp;two&nbsp;separate&nbsp;windows&nbsp;on&nbsp;your&nbsp;computer&nbsp;screen.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">THE&nbsp;DATASETS&nbsp;YOU&nbsp;NEED&nbsp;TO&nbsp;USE:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;section&nbsp;is&nbsp;about&nbsp;the&nbsp;dataset&nbsp;needs&nbsp;of&nbsp;the&nbsp;following&nbsp;two&nbsp;scripts&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;Examples&nbsp;directory&nbsp;of&nbsp;the&nbsp;distribution:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;single_instance_object_detection.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;multi_instance_object_detection.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;both&nbsp;these&nbsp;scripts,&nbsp;you&nbsp;first&nbsp;execute&nbsp;the&nbsp;following&nbsp;steps:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;&nbsp;Download&nbsp;the&nbsp;archive<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;datasets_for_YOLO.tar.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;through&nbsp;the&nbsp;link&nbsp;"Download&nbsp;the&nbsp;image&nbsp;datasets&nbsp;for&nbsp;YOLO"&nbsp;at&nbsp;the&nbsp;main<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;webpage&nbsp;for&nbsp;this&nbsp;module&nbsp;and&nbsp;store&nbsp;the&nbsp;archive&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;your&nbsp;installation&nbsp;of&nbsp;the&nbsp;module.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;&nbsp;Subsequently,&nbsp;execute&nbsp;the&nbsp;following&nbsp;command&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tar&nbsp;zxvf&nbsp;datasets_for_YOLO.tar.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;command&nbsp;will&nbsp;deposit&nbsp;the&nbsp;following&nbsp;archives&nbsp;in&nbsp;the&nbsp;"data"&nbsp;subdirectory<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;the&nbsp;Examples&nbsp;directory:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Dataset-clutter-10-noise-20-size-10000-train.gz&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Dataset-clutter-10-noise-20-size-1000-test.gz&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Dataset-clutter-5-noise-20-size-30-test.gz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Dataset-clutter-5-noise-20-size-30-train.gz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-10000-train.gz<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-1000-test.gz<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-30-test.gz<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-30-train.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Note&nbsp;the&nbsp;word&nbsp;"Multi"&nbsp;in&nbsp;the&nbsp;second&nbsp;grouping&nbsp;of&nbsp;the&nbsp;data&nbsp;archives.&nbsp;&nbsp;These<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;are&nbsp;the&nbsp;multi-instance&nbsp;versions&nbsp;of&nbsp;the&nbsp;Dr_Eval&nbsp;datasets.&nbsp;&nbsp;By<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;multi-instance&nbsp;I&nbsp;mean&nbsp;that&nbsp;you&nbsp;will&nbsp;have&nbsp;multiple&nbsp;instances&nbsp;of&nbsp;the&nbsp;three<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objects&nbsp;of&nbsp;interest&nbsp;(Dr.&nbsp;Eval,&nbsp;House,&nbsp;and&nbsp;Watertower)&nbsp;in&nbsp;each&nbsp;image.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;the&nbsp;script&nbsp;"single_instance_object_detection.py",&nbsp;you&nbsp;need&nbsp;the&nbsp;first<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;two&nbsp;archives&nbsp;in&nbsp;the&nbsp;first&nbsp;grouping&nbsp;of&nbsp;the&nbsp;four&nbsp;shown&nbsp;above.&nbsp;&nbsp;And&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;script&nbsp;"multi_instance_object_detection.py",&nbsp;you&nbsp;need&nbsp;the&nbsp;first&nbsp;two<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;archives&nbsp;in&nbsp;in&nbsp;the&nbsp;second&nbsp;grouping&nbsp;of&nbsp;the&nbsp;four.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In&nbsp;the&nbsp;naming&nbsp;convention&nbsp;used&nbsp;for&nbsp;the&nbsp;archives,&nbsp;the&nbsp;string&nbsp;'clutter-10'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;means&nbsp;that&nbsp;each&nbsp;image&nbsp;will&nbsp;have&nbsp;a&nbsp;maximum&nbsp;of&nbsp;10&nbsp;clutter&nbsp;objects&nbsp;in&nbsp;it,&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;string&nbsp;'noise-20'&nbsp;means&nbsp;that&nbsp;I&nbsp;have&nbsp;added&nbsp;20%&nbsp;Gaussian&nbsp;noise&nbsp;to&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image.&nbsp;The&nbsp;string&nbsp;'size-10000'&nbsp;means&nbsp;that&nbsp;the&nbsp;dataset&nbsp;consists&nbsp;of&nbsp;'10,000'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;images.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;rest&nbsp;of&nbsp;the&nbsp;steps&nbsp;are&nbsp;specific&nbsp;to&nbsp;whether&nbsp;you&nbsp;need&nbsp;the&nbsp;datasets&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;first&nbsp;of&nbsp;the&nbsp;two&nbsp;scripts&nbsp;listed&nbsp;at&nbsp;the&nbsp;beginning&nbsp;of&nbsp;this&nbsp;section&nbsp;or&nbsp;for&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;second.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;Datasets&nbsp;You&nbsp;Need&nbsp;for&nbsp;"single_instance_object_detection.py":<br>
&nbsp;&nbsp;&nbsp;&nbsp;--------------------------------------------------------------<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Here&nbsp;are&nbsp;the&nbsp;steps:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;3.&nbsp;&nbsp;Assuming&nbsp;you&nbsp;are&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;of&nbsp;the&nbsp;YOLOLogic&nbsp;module,&nbsp;now<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execute&nbsp;the&nbsp;following&nbsp;steps:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cd&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tar&nbsp;zxvf&nbsp;Purdue_Dr_Eval_Dataset-clutter-10-noise-20-size-10000-train.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;create&nbsp;a&nbsp;subdirectory&nbsp;named<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_dataset_train_10000<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;deposit&nbsp;the&nbsp;10,000&nbsp;training&nbsp;images&nbsp;in&nbsp;it.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;4.&nbsp;&nbsp;For&nbsp;creating&nbsp;the&nbsp;test&nbsp;dataset,&nbsp;do&nbsp;the&nbsp;following&nbsp;in&nbsp;the&nbsp;"data"&nbsp;directory:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tar&nbsp;zxvf&nbsp;Purdue_Dr_Eval_Dataset-clutter-10-noise-20-size-1000-test.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;create&nbsp;a&nbsp;subdirectory&nbsp;named<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_dataset_test_1000<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;deposit&nbsp;1000&nbsp;test&nbsp;images&nbsp;in&nbsp;it.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;IMPORTANT&nbsp;NOTE:&nbsp;The&nbsp;datasets&nbsp;used&nbsp;for&nbsp;the&nbsp;script<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"single_instance_object_detection.py"&nbsp;do&nbsp;not&nbsp;directly&nbsp;provide<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;bounding&nbsp;boxes&nbsp;(BB)&nbsp;for&nbsp;the&nbsp;object&nbsp;of&nbsp;interest&nbsp;in&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image.&nbsp;&nbsp;As&nbsp;mentioned&nbsp;on&nbsp;Slide&nbsp;82&nbsp;of&nbsp;the&nbsp;Week&nbsp;7&nbsp;lecture,&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataloader&nbsp;calculates&nbsp;the&nbsp;BB&nbsp;coordinates&nbsp;on&nbsp;the&nbsp;fly&nbsp;from&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask&nbsp;provided&nbsp;for&nbsp;the&nbsp;object&nbsp;of&nbsp;interest&nbsp;in&nbsp;each&nbsp;image.&nbsp;&nbsp;The<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dataloader&nbsp;code&nbsp;is&nbsp;shown&nbsp;on&nbsp;Slides&nbsp;84&nbsp;through&nbsp;86&nbsp;of&nbsp;the&nbsp;Week&nbsp;7<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;slides.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;As&nbsp;to&nbsp;how&nbsp;the&nbsp;data&nbsp;dataset&nbsp;is&nbsp;organized&nbsp;for&nbsp;the&nbsp;"single_instance"&nbsp;case,&nbsp;see<br>
&nbsp;&nbsp;&nbsp;&nbsp;Slide&nbsp;81&nbsp;of&nbsp;the&nbsp;Week&nbsp;7&nbsp;slides.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;Datasets&nbsp;You&nbsp;Need&nbsp;for&nbsp;"multi_instance_object_detection.py":<br>
&nbsp;&nbsp;&nbsp;&nbsp;-------------------------------------------------------------<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;5.&nbsp;&nbsp;Assuming&nbsp;you&nbsp;are&nbsp;in&nbsp;the&nbsp;Examples&nbsp;directory&nbsp;of&nbsp;the&nbsp;YOLOLogic&nbsp;module,&nbsp;now<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execute&nbsp;the&nbsp;following&nbsp;steps:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cd&nbsp;data<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tar&nbsp;zxvf&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-10000-train.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Again,&nbsp;note&nbsp;the&nbsp;word&nbsp;"Multi"&nbsp;in&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;data&nbsp;archive.&nbsp;The&nbsp;above<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;command&nbsp;will&nbsp;create&nbsp;a&nbsp;subdirectory&nbsp;named<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_multi_dataset_train_10000<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;deposit&nbsp;the&nbsp;10,000&nbsp;training&nbsp;images&nbsp;in&nbsp;it.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;6.&nbsp;&nbsp;For&nbsp;creating&nbsp;the&nbsp;test&nbsp;dataset,&nbsp;do&nbsp;the&nbsp;following&nbsp;in&nbsp;the&nbsp;"data"&nbsp;directory:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tar&nbsp;zxvf&nbsp;Purdue_Dr_Eval_Multi_Dataset-clutter-10-noise-20-size-1000-test.gz<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;will&nbsp;create&nbsp;a&nbsp;subdirectory&nbsp;named<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Purdue_Dr_Eval_multi_dataset_test_1000<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;deposit&nbsp;1000&nbsp;test&nbsp;images&nbsp;in&nbsp;it.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;See&nbsp;the&nbsp;Slides&nbsp;112&nbsp;through&nbsp;114&nbsp;of&nbsp;my&nbsp;Week&nbsp;7&nbsp;lecture&nbsp;for&nbsp;a&nbsp;description&nbsp;of&nbsp;how<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;annotations&nbsp;are&nbsp;organized&nbsp;for&nbsp;the&nbsp;"multi"&nbsp;datasets&nbsp;mentioned&nbsp;above.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">THE&nbsp;Examples&nbsp;DIRECTORY:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;directory&nbsp;contains&nbsp;the&nbsp;following&nbsp;two&nbsp;scripts&nbsp;related&nbsp;to&nbsp;object&nbsp;detection<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;images:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;single_instance_object_detection.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;multi_instance_object_detection.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;first&nbsp;script&nbsp;carries&nbsp;out&nbsp;single-instance&nbsp;detections&nbsp;in&nbsp;the&nbsp;images&nbsp;in&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;PurdueDrEvalDataset&nbsp;dataset&nbsp;and&nbsp;the&nbsp;second&nbsp;script&nbsp;carries&nbsp;out&nbsp;multi-instance<br>
&nbsp;&nbsp;&nbsp;&nbsp;detections&nbsp;in&nbsp;the&nbsp;PurdueDrEvalMultiDataset.&nbsp;&nbsp;In&nbsp;the&nbsp;former&nbsp;dataset,&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;128x128&nbsp;image&nbsp;has&nbsp;only&nbsp;one&nbsp;instance&nbsp;of&nbsp;a&nbsp;meaningful&nbsp;object&nbsp;along&nbsp;with<br>
&nbsp;&nbsp;&nbsp;&nbsp;structured&nbsp;artifacts&nbsp;and&nbsp;20%&nbsp;random&nbsp;noise.&nbsp;&nbsp;And,&nbsp;in&nbsp;the&nbsp;latter&nbsp;dataset,&nbsp;each<br>
&nbsp;&nbsp;&nbsp;&nbsp;image&nbsp;has&nbsp;up&nbsp;to&nbsp;five&nbsp;instances&nbsp;of&nbsp;meaningful&nbsp;objects&nbsp;along&nbsp;with&nbsp;the&nbsp;structured<br>
&nbsp;&nbsp;&nbsp;&nbsp;artifacts&nbsp;and&nbsp;20%&nbsp;random&nbsp;noise.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">THE&nbsp;ExamplesRegionProposals&nbsp;DIRECTORY:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;directory&nbsp;contains&nbsp;the&nbsp;following&nbsp;scripts&nbsp;for&nbsp;showcasing&nbsp;graph-based<br>
&nbsp;&nbsp;&nbsp;&nbsp;algorithms&nbsp;for&nbsp;constructing&nbsp;region&nbsp;proposals:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;selective_search.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;interactive_graph_based_segmentation.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torchvision_some_basic_transformations.py&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;torchvision_based_image_processing.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;multi_image_histogramming_and_display.py&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;ExamplesRegionProposals&nbsp;directory&nbsp;also&nbsp;illustrates&nbsp;the&nbsp;sort&nbsp;of&nbsp;region<br>
&nbsp;&nbsp;&nbsp;&nbsp;proposal&nbsp;results&nbsp;you&nbsp;can&nbsp;obtain&nbsp;with&nbsp;the&nbsp;graph-based&nbsp;algorithms&nbsp;in&nbsp;this<br>
&nbsp;&nbsp;&nbsp;&nbsp;module.&nbsp;&nbsp;The&nbsp;specific&nbsp;illustrations&nbsp;are&nbsp;in&nbsp;the&nbsp;following&nbsp;subdirectories&nbsp;of&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;ExamplesRegionProposals&nbsp;directory:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ExamplesRegionProposals/color_blobs/<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ExamplesRegionProposals/mondrian/<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ExamplesRegionProposals/wallpic2/<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Each&nbsp;subdirectory&nbsp;contains&nbsp;at&nbsp;least&nbsp;the&nbsp;following&nbsp;two&nbsp;files:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;selective_search.py<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;image&nbsp;file&nbsp;specific&nbsp;for&nbsp;that&nbsp;subdirectory.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;All&nbsp;you&nbsp;have&nbsp;to&nbsp;do&nbsp;is&nbsp;to&nbsp;execute&nbsp;selective_search.py&nbsp;in&nbsp;that&nbsp;directory&nbsp;to&nbsp;see<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;results&nbsp;on&nbsp;the&nbsp;image&nbsp;in&nbsp;that&nbsp;directory.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">BUGS:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Please&nbsp;notify&nbsp;the&nbsp;author&nbsp;if&nbsp;you&nbsp;encounter&nbsp;any&nbsp;bugs.&nbsp;&nbsp;When&nbsp;sending&nbsp;email,<br>
&nbsp;&nbsp;&nbsp;&nbsp;please&nbsp;place&nbsp;the&nbsp;string&nbsp;'YOLOLogic'&nbsp;in&nbsp;the&nbsp;subject&nbsp;line&nbsp;to&nbsp;get&nbsp;past&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;author's&nbsp;spam&nbsp;filter.<br>
&nbsp;<br>
&nbsp;<br>
<font size="+2" color="red">ABOUT&nbsp;THE&nbsp;AUTHOR:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;author,&nbsp;Avinash&nbsp;Kak,&nbsp;is&nbsp;a&nbsp;professor&nbsp;of&nbsp;Electrical&nbsp;and&nbsp;Computer&nbsp;Engineering<br>
&nbsp;&nbsp;&nbsp;&nbsp;at&nbsp;Purdue&nbsp;University.&nbsp;&nbsp;For&nbsp;all&nbsp;issues&nbsp;related&nbsp;to&nbsp;this&nbsp;module,&nbsp;contact&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;author&nbsp;at&nbsp;kak@purdue.edu&nbsp;If&nbsp;you&nbsp;send&nbsp;email,&nbsp;please&nbsp;place&nbsp;the&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;"YOLOLogic"&nbsp;in&nbsp;your&nbsp;subject&nbsp;line&nbsp;to&nbsp;get&nbsp;past&nbsp;the&nbsp;author's&nbsp;spam<br>
&nbsp;&nbsp;&nbsp;&nbsp;filter.<br>
&nbsp;<br>
<font size="+2" color="red">COPYRIGHT:<br>
</font>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Python&nbsp;Software&nbsp;Foundation&nbsp;License<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;Copyright&nbsp;2024&nbsp;Avinash&nbsp;Kak<br>
&nbsp;<br>
@endofdocs</tt></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Imported Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="torchvision.transforms.functional.html">torchvision.transforms.functional</a><br>
<a href="PIL.Image.html">PIL.Image</a><br>
<a href="PIL.ImageDraw.html">PIL.ImageDraw</a><br>
<a href="PIL.ImageFont.html">PIL.ImageFont</a><br>
<a href="PIL.ImageTk.html">PIL.ImageTk</a><br>
<a href="tkinter.html">tkinter</a><br>
<a href="copy.html">copy</a><br>
</td><td width="25%" valign=top><a href="functools.html">functools</a><br>
<a href="glob.html">glob</a><br>
<a href="logging.html">logging</a><br>
<a href="math.html">math</a><br>
<a href="torch.nn.html">torch.nn</a><br>
<a href="numpy.html">numpy</a><br>
<a href="torch.optim.html">torch.optim</a><br>
</td><td width="25%" valign=top><a href="os.html">os</a><br>
<a href="pickle.html">pickle</a><br>
<a href="matplotlib.pyplot.html">matplotlib.pyplot</a><br>
<a href="random.html">random</a><br>
<a href="re.html">re</a><br>
<a href="signal.html">signal</a><br>
<a href="sys.html">sys</a><br>
</td><td width="25%" valign=top><a href="time.html">time</a><br>
<a href="torch.html">torch</a><br>
<a href="torchvision.html">torchvision</a><br>
<a href="torchvision.utils.html">torchvision.utils</a><br>
<a href="torchvision.transforms.html">torchvision.transforms</a><br>
</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="builtins.html#object">builtins.object</a>
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="YOLOLogic.html#YOLOLogic">YOLOLogic</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="YOLOLogic">class <strong>YOLOLogic</strong></a>(<a href="builtins.html#object">builtins.object</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>YOLOLogic(*args,&nbsp;**kwargs)<br>
&nbsp;<br>
<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%">Methods defined here:<br>
<dl><dt><a name="YOLOLogic-__init__"><strong>__init__</strong></a>(self, *args, **kwargs)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(type(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<hr>
Data descriptors defined here:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>PurdueDrEvalDataset</strong> = &lt;class 'YOLOLogic.YOLOLogic.PurdueDrEvalDataset'&gt;<dd><tt>This&nbsp;is&nbsp;the&nbsp;dataset&nbsp;to&nbsp;use&nbsp;if&nbsp;you&nbsp;are&nbsp;experimenting&nbsp;with&nbsp;single-instance&nbsp;object<br>
detection.&nbsp;&nbsp;The&nbsp;dataset&nbsp;contains&nbsp;three&nbsp;kinds&nbsp;of&nbsp;objects&nbsp;in&nbsp;its&nbsp;images:<br>
Dr.&nbsp;Eval,&nbsp;and&nbsp;two&nbsp;"objects"&nbsp;in&nbsp;his&nbsp;neighborhood:&nbsp;a&nbsp;house&nbsp;and&nbsp;a&nbsp;watertower.<br>
Each&nbsp;128x128&nbsp;image&nbsp;in&nbsp;the&nbsp;dataset&nbsp;contains&nbsp;one&nbsp;of&nbsp;these&nbsp;objects&nbsp;after&nbsp;it&nbsp;is<br>
randomly&nbsp;scaled&nbsp;and&nbsp;colored&nbsp;and&nbsp;substantial&nbsp;structured&nbsp;noise&nbsp;in&nbsp;addition&nbsp;to<br>
20%&nbsp;Gaussian&nbsp;noise.&nbsp;&nbsp;Examples&nbsp;of&nbsp;these&nbsp;images&nbsp;are&nbsp;shown&nbsp;in&nbsp;Week&nbsp;8&nbsp;lecture<br>
material&nbsp;in&nbsp;Purdue's&nbsp;Deep&nbsp;Learning&nbsp;class.<br>
&nbsp;<br>
In&nbsp;order&nbsp;to&nbsp;understand&nbsp;the&nbsp;implementation&nbsp;of&nbsp;the&nbsp;dataloader&nbsp;for&nbsp;the&nbsp;Dr&nbsp;Eval<br>
dataset&nbsp;for&nbsp;single-instance-based&nbsp;object&nbsp;detection,&nbsp;note&nbsp;that&nbsp;the&nbsp;top-level<br>
directory&nbsp;for&nbsp;the&nbsp;dataset&nbsp;is&nbsp;organized&nbsp;as&nbsp;follows:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataroot<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;______________________________________________________________________<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;Dr_Eval&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;house&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;watertower&nbsp;&nbsp;&nbsp;&nbsp;mask_Dr_Eval&nbsp;&nbsp;&nbsp;&nbsp;mask_house&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask_watertower<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;images&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;images&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;images&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;binary&nbsp;images&nbsp;&nbsp;&nbsp;&nbsp;binary&nbsp;images&nbsp;&nbsp;&nbsp;binary&nbsp;images<br>
&nbsp;<br>
&nbsp;<br>
As&nbsp;you&nbsp;can&nbsp;see,&nbsp;the&nbsp;three&nbsp;main&nbsp;image&nbsp;directories&nbsp;are&nbsp;Dr_Eval,&nbsp;house,&nbsp;and<br>
watertower.&nbsp;For&nbsp;each&nbsp;image&nbsp;in&nbsp;each&nbsp;of&nbsp;these&nbsp;directories,&nbsp;the&nbsp;mask&nbsp;for&nbsp;the<br>
object&nbsp;of&nbsp;interest&nbsp;is&nbsp;supplied&nbsp;in&nbsp;the&nbsp;corresponding&nbsp;directory&nbsp;whose&nbsp;name<br>
carries&nbsp;the&nbsp;prefix&nbsp;'mask'.<br>
&nbsp;<br>
For&nbsp;example,&nbsp;if&nbsp;you&nbsp;have&nbsp;an&nbsp;image&nbsp;named&nbsp;29.jpg&nbsp;in&nbsp;the&nbsp;Dr_Eval&nbsp;directory,&nbsp;you<br>
will&nbsp;have&nbsp;an&nbsp;image&nbsp;of&nbsp;the&nbsp;same&nbsp;name&nbsp;in&nbsp;the&nbsp;mask_Dr_Eval&nbsp;directory&nbsp;that&nbsp;will<br>
just&nbsp;be&nbsp;the&nbsp;mask&nbsp;for&nbsp;the&nbsp;Dr_Eval&nbsp;object&nbsp;in&nbsp;the&nbsp;former&nbsp;image<br>
&nbsp;<br>
As&nbsp;you&nbsp;can&nbsp;see,&nbsp;the&nbsp;dataset&nbsp;does&nbsp;not&nbsp;directly&nbsp;provide&nbsp;the&nbsp;bounding&nbsp;boxes&nbsp;for<br>
object&nbsp;localization.&nbsp;&nbsp;So&nbsp;the&nbsp;implementation&nbsp;of&nbsp;the&nbsp;__getitem__()&nbsp;function&nbsp;in<br>
the&nbsp;dataloader&nbsp;must&nbsp;include&nbsp;code&nbsp;that&nbsp;calculates&nbsp;the&nbsp;bounding&nbsp;boxes&nbsp;from&nbsp;the<br>
masks.&nbsp;&nbsp;This&nbsp;you&nbsp;can&nbsp;see&nbsp;in&nbsp;the&nbsp;definition&nbsp;of&nbsp;the&nbsp;dataloader&nbsp;shown&nbsp;below.<br>
&nbsp;<br>
Since&nbsp;this&nbsp;is&nbsp;a&nbsp;``non-standard''&nbsp;organization&nbsp;of&nbsp;the&nbsp;of&nbsp;data,&nbsp;the&nbsp;dataloader<br>
must&nbsp;also&nbsp;provide&nbsp;for&nbsp;the&nbsp;indexing&nbsp;of&nbsp;the&nbsp;images&nbsp;so&nbsp;that&nbsp;they&nbsp;can&nbsp;be&nbsp;subject<br>
to&nbsp;a&nbsp;fresh&nbsp;randomization&nbsp;that&nbsp;is&nbsp;carried&nbsp;out&nbsp;by&nbsp;PyTorch's<br>
torch.utils.data.DataLoader&nbsp;class&nbsp;for&nbsp;each&nbsp;epoch&nbsp;of&nbsp;training.&nbsp;&nbsp;The<br>
index_dataset()&nbsp;function&nbsp;is&nbsp;provided&nbsp;for&nbsp;that&nbsp;purpose.<br>
&nbsp;<br>
After&nbsp;the&nbsp;dataset&nbsp;is&nbsp;downloaded&nbsp;for&nbsp;the&nbsp;first&nbsp;time,&nbsp;the&nbsp;index_dataset()<br>
function&nbsp;stores&nbsp;away&nbsp;the&nbsp;information&nbsp;as&nbsp;a&nbsp;PyTorch&nbsp;``.pt''&nbsp;file&nbsp;so&nbsp;that&nbsp;it&nbsp;can<br>
be&nbsp;downloaded&nbsp;almost&nbsp;instantaneously&nbsp;at&nbsp;subsequent&nbsp;attempts.<br>
&nbsp;<br>
One&nbsp;final&nbsp;note&nbsp;about&nbsp;the&nbsp;dataset:&nbsp;Under&nbsp;the&nbsp;hood,&nbsp;the&nbsp;dataset&nbsp;consists&nbsp;of&nbsp;the<br>
pathnames&nbsp;to&nbsp;the&nbsp;image&nbsp;files&nbsp;---&nbsp;and&nbsp;NOT&nbsp;the&nbsp;images&nbsp;themselves.&nbsp;&nbsp;It&nbsp;is&nbsp;the<br>
job&nbsp;of&nbsp;the&nbsp;multi-threaded&nbsp;``workers''&nbsp;provided&nbsp;by&nbsp;torch.utils.data.DataLoader<br>
to&nbsp;actually&nbsp;download&nbsp;the&nbsp;images&nbsp;from&nbsp;those&nbsp;pathnames.</tt></dl>

<dl><dt><strong>PurdueDrEvalMultiDataset</strong> = &lt;class 'YOLOLogic.YOLOLogic.PurdueDrEvalMultiDataset'&gt;<dd><tt>This&nbsp;is&nbsp;the&nbsp;dataset&nbsp;to&nbsp;use&nbsp;if&nbsp;you&nbsp;are&nbsp;experimenting&nbsp;with&nbsp;multi-instance&nbsp;object<br>
detection.&nbsp;&nbsp;As&nbsp;with&nbsp;the&nbsp;previous&nbsp;dataset,&nbsp;it&nbsp;contains&nbsp;three&nbsp;kinds&nbsp;of&nbsp;objects<br>
in&nbsp;its&nbsp;images:&nbsp;Dr.&nbsp;Eval,&nbsp;and&nbsp;two&nbsp;"objects"&nbsp;in&nbsp;his&nbsp;neighborhood:&nbsp;a&nbsp;house&nbsp;and&nbsp;a<br>
watertower.&nbsp;&nbsp;Each&nbsp;128x128&nbsp;image&nbsp;in&nbsp;the&nbsp;dataset&nbsp;contains&nbsp;up&nbsp;to&nbsp;5&nbsp;instances&nbsp;of<br>
these&nbsp;objects.&nbsp;The&nbsp;instances&nbsp;are&nbsp;randomly&nbsp;scaled&nbsp;and&nbsp;colored&nbsp;and&nbsp;exact&nbsp;number<br>
of&nbsp;instances&nbsp;in&nbsp;each&nbsp;image&nbsp;is&nbsp;also&nbsp;chosen&nbsp;randomly.&nbsp;Subsequently,&nbsp;background<br>
clutter&nbsp;is&nbsp;added&nbsp;to&nbsp;the&nbsp;images&nbsp;---&nbsp;these&nbsp;are&nbsp;again&nbsp;randomly&nbsp;chosen<br>
shapes.&nbsp;The&nbsp;number&nbsp;of&nbsp;clutter&nbsp;objects&nbsp;is&nbsp;also&nbsp;chosen&nbsp;randomly&nbsp;but&nbsp;cannot<br>
exceed&nbsp;10.&nbsp;&nbsp;In&nbsp;addition&nbsp;to&nbsp;the&nbsp;structured&nbsp;clutter,&nbsp;I&nbsp;add&nbsp;20%&nbsp;Gaussian&nbsp;noise<br>
to&nbsp;each&nbsp;image.&nbsp;&nbsp;Examples&nbsp;of&nbsp;these&nbsp;images&nbsp;are&nbsp;shown&nbsp;in&nbsp;Week&nbsp;8&nbsp;lecture&nbsp;material<br>
in&nbsp;Purdue's&nbsp;Deep&nbsp;Learning&nbsp;class.<br>
&nbsp;<br>
On&nbsp;account&nbsp;of&nbsp;the&nbsp;much&nbsp;richer&nbsp;structure&nbsp;of&nbsp;the&nbsp;image&nbsp;annotations,&nbsp;this<br>
dataset&nbsp;is&nbsp;organized&nbsp;very&nbsp;differently&nbsp;from&nbsp;the&nbsp;previous&nbsp;one:<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataroot<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;___________________________<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;annotations.p&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;images<br>
&nbsp;<br>
&nbsp;<br>
Since&nbsp;each&nbsp;image&nbsp;is&nbsp;allowed&nbsp;to&nbsp;contain&nbsp;instances&nbsp;of&nbsp;the&nbsp;three&nbsp;different&nbsp;types<br>
of&nbsp;"meaningful"&nbsp;objects,&nbsp;it&nbsp;is&nbsp;not&nbsp;possible&nbsp;to&nbsp;organize&nbsp;the&nbsp;images&nbsp;on&nbsp;the<br>
basis&nbsp;of&nbsp;what&nbsp;they&nbsp;contain.<br>
&nbsp;<br>
As&nbsp;for&nbsp;the&nbsp;annotations,&nbsp;the&nbsp;annotation&nbsp;for&nbsp;each&nbsp;128x128&nbsp;image&nbsp;is&nbsp;a&nbsp;dictionary<br>
that&nbsp;contains&nbsp;information&nbsp;related&nbsp;to&nbsp;all&nbsp;the&nbsp;object&nbsp;instances&nbsp;in&nbsp;the&nbsp;image.&nbsp;Here<br>
is&nbsp;an&nbsp;example&nbsp;of&nbsp;the&nbsp;annotation&nbsp;for&nbsp;an&nbsp;image&nbsp;that&nbsp;has&nbsp;three&nbsp;instances&nbsp;in&nbsp;it:<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;annotation:&nbsp;&nbsp;{'filename':&nbsp;None,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'num_objects':&nbsp;3,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'bboxes':&nbsp;{0:&nbsp;(67,&nbsp;72,&nbsp;83,&nbsp;118),&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1:&nbsp;(65,&nbsp;2,&nbsp;93,&nbsp;26),&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2:&nbsp;(16,&nbsp;68,&nbsp;53,&nbsp;122),&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3:&nbsp;None,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4:&nbsp;None},&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'bbox_labels':&nbsp;{0:&nbsp;'Dr_Eval',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1:&nbsp;'house',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2:&nbsp;'watertower',&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3:&nbsp;None,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4:&nbsp;None},&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'seg_masks':&nbsp;{0:&nbsp;&lt;PIL.Image.Image&nbsp;image&nbsp;mode=1&nbsp;size=128x128&nbsp;at&nbsp;0x7F5A06C838E0&gt;,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1:&nbsp;&lt;PIL.Image.Image&nbsp;image&nbsp;mode=1&nbsp;size=128x128&nbsp;at&nbsp;0x7F5A06C837F0&gt;,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2:&nbsp;&lt;PIL.Image.Image&nbsp;image&nbsp;mode=1&nbsp;size=128x128&nbsp;at&nbsp;0x7F5A06C838B0&gt;,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3:&nbsp;None,&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4:&nbsp;None}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br>
&nbsp;<br>
The&nbsp;annotations&nbsp;for&nbsp;the&nbsp;individual&nbsp;images&nbsp;are&nbsp;stored&nbsp;in&nbsp;a&nbsp;global&nbsp;Python<br>
dictionary&nbsp;called&nbsp;'all_annotations'&nbsp;whose&nbsp;keys&nbsp;consist&nbsp;of&nbsp;the&nbsp;pathnames&nbsp;to<br>
the&nbsp;individual&nbsp;image&nbsp;files&nbsp;and&nbsp;the&nbsp;values&nbsp;the&nbsp;annotations&nbsp;dict&nbsp;for&nbsp;the<br>
corresponding&nbsp;images.&nbsp;&nbsp;The&nbsp;filename&nbsp;shown&nbsp;above&nbsp;in&nbsp;the&nbsp;keystroke&nbsp;diagram,<br>
'annotations.p'&nbsp;is&nbsp;what&nbsp;you&nbsp;get&nbsp;by&nbsp;calling&nbsp;'pickle.dump()'&nbsp;on&nbsp;the<br>
'all_annotations'&nbsp;dictionary.</tt></dl>

<dl><dt><strong>RPN</strong> = &lt;class 'YOLOLogic.YOLOLogic.RPN'&gt;<dd><tt>This&nbsp;class&nbsp;is&nbsp;meant&nbsp;specifically&nbsp;for&nbsp;experimenting&nbsp;with&nbsp;graph-based&nbsp;algorithms&nbsp;for&nbsp;constructing&nbsp;<br>
region&nbsp;proposals&nbsp;that&nbsp;may&nbsp;be&nbsp;used&nbsp;by&nbsp;a&nbsp;neural&nbsp;network&nbsp;for&nbsp;object&nbsp;detection&nbsp;and&nbsp;localization.<br>
&nbsp;<br>
Classpath:&nbsp;&nbsp;&nbsp;&nbsp;YOLOLogic&nbsp;&nbsp;=&gt;&nbsp;&nbsp;&nbsp;RPN</tt></dl>

<dl><dt><strong>SingleInstanceDetector</strong> = &lt;class 'YOLOLogic.YOLOLogic.SingleInstanceDetector'&gt;<dd><tt>This&nbsp;class&nbsp;demonstrates&nbsp;single-instance&nbsp;object&nbsp;detection&nbsp;on&nbsp;the&nbsp;images&nbsp;in&nbsp;the<br>
PurdueDrEvalDataset&nbsp;dataset.&nbsp;&nbsp;Although&nbsp;these&nbsp;image&nbsp;are&nbsp;complex,&nbsp;in&nbsp;the&nbsp;sense<br>
that&nbsp;each&nbsp;image&nbsp;contains&nbsp;multiple&nbsp;clutter&nbsp;objects&nbsp;in&nbsp;addition&nbsp;to&nbsp;random<br>
noise,&nbsp;nonetheless&nbsp;we&nbsp;know&nbsp;that&nbsp;each&nbsp;image&nbsp;contains&nbsp;only&nbsp;a&nbsp;single&nbsp;meaningful<br>
object&nbsp;instance.&nbsp;&nbsp;The&nbsp;LOADnet&nbsp;network&nbsp;used&nbsp;for&nbsp;detection&nbsp;is&nbsp;adaptation&nbsp;of&nbsp;the<br>
the&nbsp;LOADnet2&nbsp;network&nbsp;from&nbsp;DLStudio&nbsp;to&nbsp;the&nbsp;case&nbsp;of&nbsp;128x128&nbsp;sized&nbsp;input&nbsp;images.<br>
The&nbsp;LOADnet&nbsp;network&nbsp;uses&nbsp;the&nbsp;SkipBlock&nbsp;as&nbsp;a&nbsp;building-block&nbsp;element&nbsp;for<br>
dealing&nbsp;the&nbsp;problems&nbsp;caused&nbsp;by&nbsp;vanishing&nbsp;gradients.</tt></dl>

<dl><dt><strong>YoloObjectDetector</strong> = &lt;class 'YOLOLogic.YOLOLogic.YoloObjectDetector'&gt;<dd><tt>The&nbsp;primary&nbsp;purpose&nbsp;of&nbsp;this&nbsp;class&nbsp;is&nbsp;to&nbsp;demonstrate&nbsp;multi-instance&nbsp;object&nbsp;detection&nbsp;with&nbsp;YOLO&nbsp;<br>
logic.&nbsp;&nbsp;A&nbsp;key&nbsp;parameter&nbsp;of&nbsp;the&nbsp;logic&nbsp;for&nbsp;YOLO&nbsp;based&nbsp;detection&nbsp;is&nbsp;the&nbsp;variable&nbsp;'yolo_interval'.&nbsp;&nbsp;<br>
The&nbsp;image&nbsp;gridding&nbsp;that&nbsp;is&nbsp;required&nbsp;is&nbsp;based&nbsp;on&nbsp;the&nbsp;value&nbsp;assigned&nbsp;to&nbsp;this&nbsp;variable.&nbsp;&nbsp;The&nbsp;grid&nbsp;is&nbsp;<br>
represented&nbsp;by&nbsp;an&nbsp;SxS&nbsp;array&nbsp;of&nbsp;cells&nbsp;where&nbsp;S&nbsp;is&nbsp;the&nbsp;image&nbsp;width&nbsp;divided&nbsp;by&nbsp;yolo_interval.&nbsp;So&nbsp;for<br>
images&nbsp;of&nbsp;size&nbsp;128x128&nbsp;and&nbsp;'yolo_interval=20',&nbsp;you&nbsp;will&nbsp;get&nbsp;a&nbsp;6x6&nbsp;grid&nbsp;of&nbsp;cells&nbsp;over&nbsp;the&nbsp;image.&nbsp;<br>
Since&nbsp;my&nbsp;goal&nbsp;is&nbsp;merely&nbsp;to&nbsp;illustrate&nbsp;the&nbsp;principles&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;logic,&nbsp;I&nbsp;have&nbsp;not&nbsp;bothered&nbsp;<br>
with&nbsp;the&nbsp;bottom&nbsp;8&nbsp;rows&nbsp;and&nbsp;the&nbsp;right-most&nbsp;8&nbsp;columns&nbsp;of&nbsp;the&nbsp;image&nbsp;that&nbsp;get&nbsp;left&nbsp;out&nbsp;of&nbsp;the&nbsp;area&nbsp;<br>
covered&nbsp;by&nbsp;such&nbsp;a&nbsp;grid.<br>
&nbsp;<br>
An&nbsp;important&nbsp;element&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;logic&nbsp;is&nbsp;defining&nbsp;a&nbsp;set&nbsp;of&nbsp;Anchor&nbsp;Boxes&nbsp;for&nbsp;each&nbsp;cell&nbsp;in&nbsp;the&nbsp;SxS&nbsp;<br>
grid.&nbsp;&nbsp;The&nbsp;anchor&nbsp;boxes&nbsp;are&nbsp;characterized&nbsp;by&nbsp;their&nbsp;aspect&nbsp;ratios.&nbsp;&nbsp;By&nbsp;aspect&nbsp;ratio&nbsp;I&nbsp;mean&nbsp;the<br>
'height/width'&nbsp;characterization&nbsp;of&nbsp;the&nbsp;boxes.&nbsp;&nbsp;My&nbsp;implementation&nbsp;provides&nbsp;for&nbsp;5&nbsp;anchor&nbsp;boxes&nbsp;for&nbsp;<br>
each&nbsp;cell&nbsp;with&nbsp;the&nbsp;following&nbsp;aspect&nbsp;ratios:&nbsp;1/5,&nbsp;1/3,&nbsp;1/1,&nbsp;3/1,&nbsp;5/1.&nbsp;&nbsp;<br>
&nbsp;<br>
At&nbsp;training&nbsp;time,&nbsp;each&nbsp;instance&nbsp;in&nbsp;the&nbsp;image&nbsp;is&nbsp;assigned&nbsp;to&nbsp;that&nbsp;cell&nbsp;whose&nbsp;central&nbsp;pixel&nbsp;is&nbsp;<br>
closest&nbsp;to&nbsp;the&nbsp;center&nbsp;of&nbsp;the&nbsp;bounding&nbsp;box&nbsp;for&nbsp;the&nbsp;instance.&nbsp;After&nbsp;the&nbsp;cell&nbsp;assignment,&nbsp;the&nbsp;<br>
instance&nbsp;is&nbsp;assigned&nbsp;to&nbsp;that&nbsp;anchor&nbsp;box&nbsp;whose&nbsp;aspect&nbsp;ratio&nbsp;comes&nbsp;closest&nbsp;to&nbsp;matching&nbsp;the&nbsp;aspect&nbsp;<br>
ratio&nbsp;of&nbsp;the&nbsp;instance.<br>
&nbsp;<br>
The&nbsp;assigning&nbsp;of&nbsp;an&nbsp;object&nbsp;instance&nbsp;to&nbsp;a&nbsp;&lt;cell,&nbsp;anchor_box&gt;&nbsp;pair&nbsp;is&nbsp;encoded&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;a&nbsp;<br>
'5+C'&nbsp;element&nbsp;long&nbsp;YOLO&nbsp;vector&nbsp;where&nbsp;C&nbsp;is&nbsp;the&nbsp;number&nbsp;of&nbsp;classes&nbsp;for&nbsp;the&nbsp;object&nbsp;instances.&nbsp;&nbsp;<br>
In&nbsp;our&nbsp;cases,&nbsp;C&nbsp;is&nbsp;3&nbsp;for&nbsp;the&nbsp;three&nbsp;classes&nbsp;'Dr_Eval',&nbsp;'house'&nbsp;and&nbsp;'watertower',&nbsp;therefore&nbsp;we&nbsp;<br>
end&nbsp;up&nbsp;with&nbsp;an&nbsp;8-element&nbsp;vector&nbsp;encoding&nbsp;when&nbsp;we&nbsp;assign&nbsp;an&nbsp;instance&nbsp;to&nbsp;a&nbsp;&lt;cell,&nbsp;anchor_box&gt;&nbsp;<br>
pair.&nbsp;&nbsp;The&nbsp;last&nbsp;C&nbsp;elements&nbsp;of&nbsp;the&nbsp;encoding&nbsp;vector&nbsp;can&nbsp;be&nbsp;thought&nbsp;as&nbsp;a&nbsp;one-hot&nbsp;representation&nbsp;<br>
of&nbsp;the&nbsp;class&nbsp;label&nbsp;for&nbsp;the&nbsp;instance.<br>
&nbsp;<br>
The&nbsp;first&nbsp;five&nbsp;elements&nbsp;of&nbsp;the&nbsp;vector&nbsp;encoding&nbsp;for&nbsp;each&nbsp;anchor&nbsp;box&nbsp;in&nbsp;a&nbsp;cell&nbsp;are&nbsp;set&nbsp;as&nbsp;follows:&nbsp;<br>
The&nbsp;first&nbsp;element&nbsp;is&nbsp;set&nbsp;to&nbsp;1&nbsp;if&nbsp;an&nbsp;object&nbsp;instance&nbsp;was&nbsp;actually&nbsp;assigned&nbsp;to&nbsp;that&nbsp;anchor&nbsp;box.&nbsp;<br>
The&nbsp;next&nbsp;two&nbsp;elements&nbsp;are&nbsp;the&nbsp;(x,y)&nbsp;displacements&nbsp;of&nbsp;the&nbsp;center&nbsp;of&nbsp;the&nbsp;actual&nbsp;bounding&nbsp;box&nbsp;<br>
for&nbsp;the&nbsp;object&nbsp;instance&nbsp;vis-a-vis&nbsp;the&nbsp;center&nbsp;of&nbsp;the&nbsp;cell.&nbsp;These&nbsp;two&nbsp;displacements&nbsp;are&nbsp;expressed&nbsp;<br>
as&nbsp;a&nbsp;fraction&nbsp;of&nbsp;the&nbsp;width&nbsp;and&nbsp;the&nbsp;height&nbsp;of&nbsp;the&nbsp;cell.&nbsp;&nbsp;The&nbsp;next&nbsp;two&nbsp;elements&nbsp;of&nbsp;the&nbsp;YOLO&nbsp;vector<br>
are&nbsp;the&nbsp;actual&nbsp;height&nbsp;and&nbsp;the&nbsp;actual&nbsp;width&nbsp;of&nbsp;the&nbsp;true&nbsp;bounding&nbsp;box&nbsp;for&nbsp;the&nbsp;instance&nbsp;in&nbsp;question&nbsp;<br>
as&nbsp;a&nbsp;multiple&nbsp;of&nbsp;the&nbsp;cell&nbsp;dimension.<br>
&nbsp;<br>
The&nbsp;8-element&nbsp;YOLO&nbsp;vectors&nbsp;are&nbsp;packed&nbsp;into&nbsp;a&nbsp;YOLO&nbsp;tensor&nbsp;of&nbsp;shape&nbsp;(num_cells,&nbsp;num_anch_boxes,&nbsp;8)<br>
where&nbsp;num_cell&nbsp;is&nbsp;36&nbsp;for&nbsp;a&nbsp;6x6&nbsp;gridding&nbsp;of&nbsp;an&nbsp;image,&nbsp;num_anch_boxes&nbsp;is&nbsp;5.<br>
&nbsp;<br>
Classpath:&nbsp;&nbsp;YOLOLogic&nbsp;&nbsp;-&gt;&nbsp;&nbsp;YoloObjectDetector</tt></dl>

<dl><dt><strong>canvas</strong> = None</dl>

<dl><dt><strong>drawEnable</strong> = 0</dl>

<dl><dt><strong>region_mark_coords</strong> = {}</dl>

<dl><dt><strong>startX</strong> = 0</dl>

<dl><dt><strong>startY</strong> = 0</dl>

</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-ctrl_c_handler"><strong>ctrl_c_handler</strong></a>(signum, frame)</dt></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>

p<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>__author__</strong> = 'Avinash Kak (kak@purdue.edu)'<br>
<strong>__copyright__</strong> = '(C) 2024 Avinash Kak. Python Software Foundation.'<br>
<strong>__date__</strong> = '2024-February-28'<br>
<strong>__url__</strong> = 'https://engineering.purdue.edu/kak/distYOLO/YOLOLogic-2.1.4.html'<br>
<strong>__version__</strong> = '2.1.4'</td></tr></table>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#7799ee">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Author</strong></big></font></td></tr>
<tr><td bgcolor="#7799ee"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%">Avinash&nbsp;Kak&nbsp;(kak@purdue.edu)</td></tr></table>
</body></html>
