{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../obj_det/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth\n"
     ]
    }
   ],
   "source": [
    "# !mim download mmdet --config mask-rcnn_swin-t-p4-w7_fpn_1x_coco --dest .\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from mmdet.apis import init_detector #, inference_detector\n",
    "from mmengine.config import Config\n",
    "\n",
    "from split_utils import SplitSwinTransformer, SplitTwoStageDetector, TwoInputIdentity\n",
    "\n",
    "config_file = '../obj_det/mask-rcnn_swin-t-p4-w7_fpn_1x_coco.py'\n",
    "checkpoint_file = '../obj_det/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth'\n",
    "\n",
    "model_init = init_detector(config_file, checkpoint_file, device='cpu')  # or device='cuda:0'\n",
    "# result = inference_detector(model, 'demo/demo.jpg')\n",
    "\n",
    "# from mmdet.registry import MODELS\n",
    "# MODELS.get('SwinTransformer')\n",
    "# MODELS.get('TwoStageDetector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('/obj_det/mask-rcnn_swin-t-p4-w7_fpn_1x_coco.py')\n",
    "model = SplitTwoStageDetector.create_from_instance_and_cfg(model_init, cfg, cut_point=1)\n",
    "\n",
    "prp = model.data_preprocessor\n",
    "model.data_preprocessor = TwoInputIdentity()\n",
    "\n",
    "# model.backbone = SplitSwinTransformer.create_from_instance_and_cfg(model.backbone, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../obj_det/mask_rcnn_swin-t-p4-w7_fpn_1x_coco_20210902_120937-9d6b7cfa.pth\n"
     ]
    }
   ],
   "source": [
    "model2 = SplitTwoStageDetector.create_from_cfg_and_checkpoint(config_file, checkpoint_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/01 09:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.5 (default, May 30 2022, 18:17:32) [GCC 7.5.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 92037769\n",
      "    GPU 0: NVIDIA GeForce RTX 2080 Ti\n",
      "    CUDA_HOME: /usr/local/cuda-10.1\n",
      "    NVCC: Cuda compilation tools, release 10.1, V10.1.24\n",
      "    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "    PyTorch: 1.8.1+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 92037769\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch2/aharell/CFM-Task-Models/.venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /local-scratch2/aharell/CFM-Task-Models/.venv/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c106IValue23reportToTensorTypeErrorEv\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/01 09:17:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 12\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        convert_weights=True,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            6,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.2,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=96,\n",
      "        init_cfg=None,\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            3,\n",
      "            6,\n",
      "            12,\n",
      "            24,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=7,\n",
      "        with_cp=False),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            96,\n",
      "            192,\n",
      "            384,\n",
      "            768,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=80,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        mask_head=dict(\n",
      "            conv_out_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_mask=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "            num_classes=80,\n",
      "            num_convs=4,\n",
      "            type='FCNMaskHead'),\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        test_cfg=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='MaskRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.0001, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1000, start_factor=0.001,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_train2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train2017/'),\n",
      "        data_root='../../data/coco/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './logs'\n",
      "\n",
      "03/01 09:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/01 09:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmdet.utils import get_test_pipeline_cfg\n",
    "\n",
    "from mmcv.transforms import Compose\n",
    "\n",
    "cfg = model_init.cfg.copy()\n",
    "test_pipeline = get_test_pipeline_cfg(cfg)\n",
    "\n",
    "test_pipeline = Compose(test_pipeline)\n",
    "\n",
    "# data_ = dict(img_path='demo/demo.jpg', img_id=0)\n",
    "\n",
    "\n",
    "cfg_tr = cfg.copy()\n",
    "cfg_tr['work_dir'] = './logs'\n",
    "cfg_tr['train_dataloader']['dataset']['data_root'] = '../data/coco/'\n",
    "# print(list(cfg_tr.train_dataloader.keys()))\n",
    "runner = RUNNERS.build(cfg_tr)\n",
    "# print(cfg_tr.train_dataloader)\n",
    "# with open('data/coco/annotations/instances_train2017.json', 'r') as file:\n",
    "#     data_json = json.load(file)\n",
    "\n",
    "\n",
    "# data_ = train_pipeline(data_json)\n",
    "\n",
    "# data_['inputs'] = data_['inputs'].unsqueeze(0)\n",
    "# data_['data_samples'] = [data_['data_samples']]\n",
    "\n",
    "# print(train_pipeline)\n",
    "# print(list(data_json.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=12.75s)\n",
      "creating index...\n",
      "index created!\n",
      "1\n",
      "(tensor(0.7063, grad_fn=<AddBackward0>), OrderedDict([('loss', tensor(0.7063, grad_fn=<AddBackward0>)), ('loss_rpn_cls', tensor(0.0172, grad_fn=<AddBackward0>)), ('loss_rpn_bbox', tensor(0.0275, grad_fn=<AddBackward0>)), ('loss_cls', tensor(0.1790, grad_fn=<MeanBackward0>)), ('acc', tensor(92.3828)), ('loss_bbox', tensor(0.2093, grad_fn=<MeanBackward0>)), ('loss_mask', tensor(0.2733, grad_fn=<MeanBackward0>))]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dl = runner.train_dataloader\n",
    "print(model.cut_point)\n",
    "for i,data in enumerate(dl):\n",
    "    model.zero_grad()\n",
    "    model.eval()\n",
    "    # im['inputs'] = torch.stack(im['inputs'])\n",
    "    # print(list(data_.keys()))\n",
    "    # data_ = train_pipeline(im)\n",
    "    # data_ = prp(data_, False)\n",
    "    # data_['inputs'] = model.backbone.split_forward_v2(data_['inputs'], output_layer=model.cut_point-1)\n",
    "    # data_['inputs'] = {\n",
    "    #                \"hw_shape\": data_['inputs'][0],\n",
    "    #                \"outs\": data_['inputs'][1]}\n",
    "    data = model.feature_frontend(data)\n",
    "    print(model.backend_loss(data))\n",
    "    # losses = model.loss(data_['inputs'], data_['data_samples'])\n",
    "    # loss, losses = model.parse_losses(losses)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ = prp(data_, False)\n",
    "# data_['inputs'] = model.backbone.split_forward(data_['inputs'], output_layer=model.cut_point-1)\n",
    "# data_['inputs'] = {\"x\": data_['inputs'][0],\n",
    "                #    \"hw_shape\": data_['inputs'][1],\n",
    "                #    \"outs\": data_['inputs'][2]}\n",
    "\n",
    "# data_['inputs'] = [data_['inputs']]\n",
    "# data_['data_samples'] = [data_['data_samples']]\n",
    "\n",
    "# # forward the model\n",
    "with torch.no_grad():\n",
    "    results = model.test_step(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinBlockSequence(\n",
       "  (blocks): ModuleList(\n",
       "    (0): SwinBlock(\n",
       "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ShiftWindowMSA(\n",
       "        (w_msa): WindowMSA(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop): DropPath()\n",
       "      )\n",
       "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (dropout_layer): DropPath()\n",
       "        (gamma2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SwinBlock(\n",
       "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ShiftWindowMSA(\n",
       "        (w_msa): WindowMSA(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop): DropPath()\n",
       "      )\n",
       "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (dropout_layer): DropPath()\n",
       "        (gamma2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downsample): PatchMerging(\n",
       "    (adap_padding): AdaptivePadding()\n",
       "    (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone.stages[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b048090fc6d3014cd2bdcc9ea88274151058c974d3dd655c4d5f3eddfe0b65cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
